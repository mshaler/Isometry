name: ETL Pipeline Testing

# Comprehensive CI/CD pipeline for ETL import testing with sql.js integration
# Tests all importers with data integrity validation, regression detection, and sql.js compatibility

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/db/**'
      - 'src/services/**'
      - 'native/Sources/Isometry/Import/**'
      - 'native/Sources/Isometry/ETL/**'
      - 'native/Tests/IsometryTests/ETL/**'
      - 'scripts/etl-test-data-setup.sh'
      - '.github/workflows/etl-testing.yml'

  pull_request:
    branches: [main, develop]
    paths:
      - 'src/db/**'
      - 'src/services/**'
      - 'native/Sources/Isometry/Import/**'
      - 'native/Sources/Isometry/ETL/**'
      - 'native/Tests/IsometryTests/ETL/**'
      - 'scripts/etl-test-data-setup.sh'
      - '.github/workflows/etl-testing.yml'

  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'

  workflow_dispatch:
    inputs:
      test_scope:
        description: 'Test scope to run'
        required: true
        default: 'comprehensive'
        type: choice
        options:
          - fast
          - comprehensive
          - fuzzing-only
          - regression-only
          - performance-only

      test_iterations:
        description: 'Number of fuzzing iterations (for fuzzing tests)'
        required: false
        default: '1000'
        type: string

      enable_performance_regression:
        description: 'Enable performance regression detection'
        required: false
        default: true
        type: boolean

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  # Test configuration
  NODE_VERSION: '18'
  SWIFT_VERSION: '5.9'
  PERFORMANCE_REGRESSION_THRESHOLD: '1.5'
  MAX_TEST_DURATION_MINUTES: '20'

  # Performance baselines
  BASELINE_BRANCH: 'main'
  PERFORMANCE_BASELINE_DAYS: '7'

  # Test data configuration
  TEST_DATA_CACHE_VERSION: 'v2'
  LFS_CACHE_VERSION: 'v2'

  # sql.js configuration
  SQLJS_VERSION: 'latest'
  ENABLE_FTS5: 'true'
  ENABLE_RECURSIVE_CTE: 'true'

jobs:
  # Job 1: Setup and validate test environment
  setup:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    outputs:
      test-scope: ${{ steps.determine-scope.outputs.scope }}
      matrix-platforms: ${{ steps.determine-scope.outputs.platforms }}
      test-iterations: ${{ steps.determine-scope.outputs.iterations }}
      cache-key: ${{ steps.cache-keys.outputs.test-data-key }}
      lfs-cache-key: ${{ steps.cache-keys.outputs.lfs-key }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need recent history for change detection

      - name: Determine test scope
        id: determine-scope
        run: |
          # Determine test scope based on trigger and inputs
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            SCOPE="${{ inputs.test_scope }}"
            ITERATIONS="${{ inputs.test_iterations }}"
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            SCOPE="comprehensive"
            ITERATIONS="2000"
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            # Fast tests for PRs
            SCOPE="fast"
            ITERATIONS="500"
          else
            # Push to main/develop - comprehensive tests
            SCOPE="comprehensive"
            ITERATIONS="1000"
          fi

          # Determine platform matrix based on scope
          case "$SCOPE" in
            fast)
              PLATFORMS='["macos-14"]'  # Only macOS for fast tests
              ;;
            comprehensive)
              PLATFORMS='["macos-14", "macos-13", "ubuntu-latest"]'  # Full matrix
              ;;
            fuzzing-only|regression-only|performance-only)
              PLATFORMS='["macos-14", "ubuntu-latest"]'  # Reduced matrix for specific tests
              ;;
          esac

          echo "scope=$SCOPE" >> $GITHUB_OUTPUT
          echo "platforms=$PLATFORMS" >> $GITHUB_OUTPUT
          echo "iterations=$ITERATIONS" >> $GITHUB_OUTPUT

          echo "üìä Test Configuration:"
          echo "  Scope: $SCOPE"
          echo "  Platforms: $PLATFORMS"
          echo "  Iterations: $ITERATIONS"

      - name: Generate cache keys
        id: cache-keys
        run: |
          # Generate cache keys for test data and LFS
          TEST_DATA_KEY="test-data-${{ env.TEST_DATA_CACHE_VERSION }}-${{ hashFiles('test-data/**/*.json', 'test-data/**/*.md', 'test-data/**/*.html') }}"
          LFS_KEY="lfs-${{ env.LFS_CACHE_VERSION }}-${{ hashFiles('.gitattributes', 'test-data/**') }}"

          echo "test-data-key=$TEST_DATA_KEY" >> $GITHUB_OUTPUT
          echo "lfs-key=$LFS_KEY" >> $GITHUB_OUTPUT

      - name: Validate test environment
        run: |
          echo "üîç Validating test environment..."

          # Check required files and directories
          if [[ ! -f "scripts/etl-test-data-setup.sh" ]]; then
            echo "‚ùå ETL test data setup script not found"
            exit 1
          fi

          # Check sql.js integration paths
          if [[ ! -d "src/db" ]]; then
            echo "‚ùå sql.js database directory not found"
            exit 1
          fi

          if [[ ! -f "src/db/schema.sql" ]]; then
            echo "‚ùå Database schema file not found"
            exit 1
          fi

          # Check native ETL sources (if they exist)
          if [[ -d "native/Sources/Isometry/Import" ]]; then
            echo "‚úÖ Native import sources found"
          fi

          if [[ -d "native/Sources/Isometry/ETL" ]]; then
            echo "‚úÖ Native ETL sources found"
          fi

          if [[ -d "native/Tests/IsometryTests/ETL" ]]; then
            echo "‚úÖ Native ETL tests found"
          fi

          echo "‚úÖ Test environment validation passed"

  # Job 2: Fast validation tests (for PRs)
  fast-validation:
    name: Fast Validation
    runs-on: macos-14
    needs: setup
    if: needs.setup.outputs.test-scope == 'fast'
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: false  # Fast tests don't need LFS

      - name: Setup Swift
        uses: swift-actions/setup-swift@v1
        with:
          swift-version: ${{ env.SWIFT_VERSION }}

      - name: Cache test data
        uses: actions/cache@v3
        with:
          path: test-data/downloads/cache
          key: ${{ needs.setup.outputs.cache-key }}-fast
          restore-keys: |
            test-data-${{ env.TEST_DATA_CACHE_VERSION }}-

      - name: Setup test data (fast)
        run: |
          echo "‚ö° Setting up fast test data..."
          ./scripts/etl-test-data-setup.sh --ci-only
          ./test-data/downloads/download-for-ci.sh fast

      - name: Run fast import tests
        run: |
          echo "üèÉ‚Äç‚ôÇÔ∏è Running fast validation tests..."
          cd native

          # Run basic import tests only
          swift test --filter "PropertyBasedImportTests" --parallel

          echo "‚úÖ Fast validation completed"

      - name: Upload fast test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: fast-test-results
          path: |
            native/.build/debug/test-results.xml
            native/.build/debug/test-logs/

  # Job 2.5: sql.js ETL Testing
  sqljs-etl-testing:
    name: sql.js ETL Testing
    runs-on: ubuntu-latest
    needs: setup
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Verify sql.js capabilities
        run: |
          echo "üîç Verifying sql.js capabilities..."
          npm run test:run -- --grep "sql.js capabilities|FTS5|recursive CTE" || true

      - name: Run sql.js ETL tests
        run: |
          echo "üß™ Running sql.js ETL integration tests..."

          # Test database initialization
          npm run test:run -- --grep "database.*init" || true

          # Test schema loading
          npm run test:run -- --grep "schema.*load" || true

          # Test import functionality
          npm run test:run -- --grep "import.*test" || true

      - name: Test ETL data integrity
        run: |
          echo "üìä Testing ETL data integrity with sql.js..."

          # Run data integrity tests if they exist
          if npm run test:run -- --grep "data.*integrity" 2>/dev/null; then
            echo "‚úÖ Data integrity tests passed"
          else
            echo "‚ÑπÔ∏è No data integrity tests found"
          fi

      - name: Upload sql.js ETL results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: sqljs-etl-results
          path: |
            coverage/
            test-results.xml
            *.log
          retention-days: 7

  # Job 3: Comprehensive ETL testing matrix
  etl-testing:
    name: ETL Testing (${{ matrix.platform }})
    runs-on: ${{ matrix.platform }}
    needs: setup
    if: needs.setup.outputs.test-scope != 'fast'
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        platform: ${{ fromJson(needs.setup.outputs.matrix-platforms) }}

    env:
      PLATFORM: ${{ matrix.platform }}
      ITERATIONS: ${{ needs.setup.outputs.test-iterations }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 0  # Full history for baseline comparison

      - name: Setup Swift (macOS)
        if: startsWith(matrix.platform, 'macos')
        uses: swift-actions/setup-swift@v1
        with:
          swift-version: ${{ env.SWIFT_VERSION }}

      - name: Setup Swift (Linux)
        if: startsWith(matrix.platform, 'ubuntu')
        run: |
          # Install Swift on Linux
          wget -q -O - https://swift.org/keys/all-keys.asc | gpg --import -
          wget https://download.swift.org/swift-${{ env.SWIFT_VERSION }}-release/ubuntu2204/swift-${{ env.SWIFT_VERSION }}-RELEASE/swift-${{ env.SWIFT_VERSION }}-RELEASE-ubuntu22.04.tar.gz
          tar xzf swift-${{ env.SWIFT_VERSION }}-RELEASE-ubuntu22.04.tar.gz
          echo "${PWD}/swift-${{ env.SWIFT_VERSION }}-RELEASE-ubuntu22.04/usr/bin" >> $GITHUB_PATH

      - name: Cache Git LFS
        uses: actions/cache@v3
        with:
          path: .git/lfs
          key: ${{ needs.setup.outputs.lfs-cache-key }}-${{ matrix.platform }}
          restore-keys: |
            lfs-${{ env.LFS_CACHE_VERSION }}-${{ matrix.platform }}-
            lfs-${{ env.LFS_CACHE_VERSION }}-

      - name: Cache test data
        uses: actions/cache@v3
        with:
          path: |
            test-data/downloads/cache
            test-data/benchmarks
          key: ${{ needs.setup.outputs.cache-key }}-${{ matrix.platform }}
          restore-keys: |
            test-data-${{ env.TEST_DATA_CACHE_VERSION }}-${{ matrix.platform }}-
            test-data-${{ env.TEST_DATA_CACHE_VERSION }}-

      - name: Cache Swift build
        uses: actions/cache@v3
        with:
          path: native/.build
          key: swift-build-${{ matrix.platform }}-${{ hashFiles('native/Package.swift', 'native/Package.resolved') }}
          restore-keys: |
            swift-build-${{ matrix.platform }}-

      - name: Setup test data repository
        run: |
          echo "üì¶ Setting up test data repository for ${{ matrix.platform }}..."
          ./scripts/etl-test-data-setup.sh

          # Download full test data for comprehensive testing
          if [[ "${{ needs.setup.outputs.test-scope }}" == "comprehensive" ]]; then
            ./test-data/downloads/download-for-ci.sh full
          else
            ./test-data/downloads/download-for-ci.sh fast
          fi

      - name: Build ETL testing framework
        run: |
          echo "üî® Building ETL testing framework..."
          cd native

          # Build in release mode for performance testing
          swift build --configuration release

          echo "‚úÖ Build completed"

      - name: Run Property-Based Import Tests
        if: contains(fromJson('["comprehensive", "fuzzing-only"]'), needs.setup.outputs.test-scope)
        run: |
          echo "üß™ Running property-based import tests..."
          cd native

          # Set test environment variables
          export ETL_TEST_ITERATIONS=${{ env.ITERATIONS }}
          export ETL_TEST_PLATFORM="${{ matrix.platform }}"
          export ETL_PERFORMANCE_REGRESSION_THRESHOLD="${{ env.PERFORMANCE_REGRESSION_THRESHOLD }}"

          # Run property-based tests
          swift test --configuration release --filter "PropertyBasedImportTests" --parallel

          echo "‚úÖ Property-based tests completed"

      - name: Run Fuzzing Tests
        if: contains(fromJson('["comprehensive", "fuzzing-only"]'), needs.setup.outputs.test-scope)
        run: |
          echo "üî• Running fuzzing tests..."
          cd native

          # Set fuzzing environment variables
          export FUZZ_TEST_ITERATIONS=${{ env.ITERATIONS }}
          export FUZZ_STATISTICAL_CONFIDENCE="0.95"
          export FUZZ_TARGET_COVERAGE="0.95"

          # Run fuzzing tests
          swift test --configuration release --filter "FuzzTestEngineTests" --parallel

          echo "‚úÖ Fuzzing tests completed"

      - name: Run Data Integrity Validation
        if: contains(fromJson('["comprehensive", "regression-only"]'), needs.setup.outputs.test-scope)
        run: |
          echo "üìä Running data integrity validation..."
          cd native

          # Set validation environment variables
          export DATA_INTEGRITY_SAMPLE_SIZE="100"
          export DATA_INTEGRITY_CONFIDENCE_LEVEL="0.95"
          export DATA_PRESERVATION_THRESHOLD="0.999"
          export LATCH_MAPPING_THRESHOLD="0.95"

          # Run data integrity tests
          swift test --configuration release --filter "DataIntegrityValidatorTests" --parallel

          echo "‚úÖ Data integrity validation completed"

      - name: Run Regression Tests
        if: contains(fromJson('["comprehensive", "regression-only"]'), needs.setup.outputs.test-scope)
        run: |
          echo "üîç Running regression tests..."
          cd native

          # Set regression test environment variables
          export REGRESSION_TEST_ALL_DATASETS="true"
          export REGRESSION_DETECTION_THRESHOLD="0.90"
          export REGRESSION_GITHUB_INTEGRATION="false"  # Disable in CI

          # Run regression tests
          swift test --configuration release --filter "RegressionTestSuiteTests" --parallel

          echo "‚úÖ Regression tests completed"

      - name: Run Round-Trip Validation Tests
        run: |
          echo "üîÑ Running round-trip validation tests..."
          cd native

          # Set round-trip test environment variables
          export ROUND_TRIP_ACCURACY_THRESHOLD="0.999"
          export ROUND_TRIP_LATCH_THRESHOLD="0.95"
          export ROUND_TRIP_SAMPLE_SIZE="50"

          # Run round-trip tests
          swift test --configuration release --filter "RoundTripValidationTests" --parallel

          echo "‚úÖ Round-trip validation completed"

      - name: Performance Regression Detection
        if: ${{ inputs.enable_performance_regression == true || github.event_name == 'schedule' }}
        run: |
          echo "‚ö° Running performance regression detection..."
          cd native

          # Set performance test environment variables
          export PERFORMANCE_BASELINE_BRANCH="${{ env.BASELINE_BRANCH }}"
          export PERFORMANCE_REGRESSION_THRESHOLD="${{ env.PERFORMANCE_REGRESSION_THRESHOLD }}"
          export PERFORMANCE_BASELINE_DAYS="${{ env.PERFORMANCE_BASELINE_DAYS }}"

          # Run performance tests and detect regressions
          swift test --configuration release --filter "ImportPerformanceTests" --parallel

          echo "‚úÖ Performance regression detection completed"

      - name: Generate Test Report
        if: always()
        run: |
          echo "üìã Generating comprehensive test report..."
          cd native

          # Generate test report
          cat > test-report-${{ matrix.platform }}.md << EOF
          # ETL Testing Report - ${{ matrix.platform }}

          **Test Scope:** ${{ needs.setup.outputs.test-scope }}
          **Platform:** ${{ matrix.platform }}
          **Iterations:** ${{ env.ITERATIONS }}
          **Swift Version:** ${{ env.SWIFT_VERSION }}
          **Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')

          ## Test Results Summary

          EOF

          # Add test results if available
          if [[ -f ".build/debug/test-results.xml" ]]; then
            echo "### Test Execution Results" >> test-report-${{ matrix.platform }}.md
            echo '```xml' >> test-report-${{ matrix.platform }}.md
            head -50 .build/debug/test-results.xml >> test-report-${{ matrix.platform }}.md
            echo '```' >> test-report-${{ matrix.platform }}.md
          fi

          echo "üìã Test report generated: test-report-${{ matrix.platform }}.md"

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: etl-test-results-${{ matrix.platform }}
          path: |
            native/.build/debug/test-results.xml
            native/.build/debug/test-logs/
            native/test-report-${{ matrix.platform }}.md
          retention-days: 30

      - name: Upload Performance Data
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-data-${{ matrix.platform }}
          path: |
            native/.build/debug/performance-*.json
            native/.build/debug/baseline-*.json
          retention-days: 90

  # Job 4: Aggregate results and generate comprehensive report
  aggregate-results:
    name: Aggregate Test Results
    runs-on: ubuntu-latest
    needs: [setup, sqljs-etl-testing, etl-testing]
    if: always() && needs.setup.outputs.test-scope != 'fast'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test results
        uses: actions/download-artifact@v3
        with:
          path: test-results/

      - name: Generate comprehensive report
        run: |
          echo "üìä Generating comprehensive ETL test report..."

          cat > comprehensive-etl-report.md << EOF
          # Comprehensive ETL Pipeline Test Report

          **Workflow:** ${{ github.workflow }}
          **Run ID:** ${{ github.run_id }}
          **Test Scope:** ${{ needs.setup.outputs.test-scope }}
          **Trigger:** ${{ github.event_name }}
          **Branch/PR:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')

          ## Test Configuration

          - **Platforms Tested:** ${{ needs.setup.outputs.matrix-platforms }}
          - **Fuzzing Iterations:** ${{ needs.setup.outputs.test-iterations }}
          - **Performance Regression Threshold:** ${{ env.PERFORMANCE_REGRESSION_THRESHOLD }}x
          - **Swift Version:** ${{ env.SWIFT_VERSION }}

          ## Test Results by Platform

          EOF

          # Process results from each platform
          for platform_dir in test-results/etl-test-results-*/; do
            if [[ -d "$platform_dir" ]]; then
              platform=$(basename "$platform_dir" | sed 's/etl-test-results-//')
              echo "### $platform" >> comprehensive-etl-report.md

              if [[ -f "$platform_dir/test-report-$platform.md" ]]; then
                echo "" >> comprehensive-etl-report.md
                cat "$platform_dir/test-report-$platform.md" >> comprehensive-etl-report.md
                echo "" >> comprehensive-etl-report.md
              fi
            fi
          done

          # Add performance analysis if available
          echo "## Performance Analysis" >> comprehensive-etl-report.md
          echo "" >> comprehensive-etl-report.md

          performance_files=(test-results/performance-data-*/performance-*.json)
          if [[ ${#performance_files[@]} -gt 0 && -f "${performance_files[0]}" ]]; then
            echo "Performance data collected from ${#performance_files[@]} platforms." >> comprehensive-etl-report.md
            echo "" >> comprehensive-etl-report.md

            # Add link to detailed performance data
            echo "üìà Detailed performance data available in artifacts." >> comprehensive-etl-report.md
          else
            echo "No performance data available for this run." >> comprehensive-etl-report.md
          fi

          echo "" >> comprehensive-etl-report.md
          echo "## Artifacts" >> comprehensive-etl-report.md
          echo "" >> comprehensive-etl-report.md
          echo "- Test results and logs: See 'etl-test-results-*' artifacts" >> comprehensive-etl-report.md
          echo "- Performance data: See 'performance-data-*' artifacts" >> comprehensive-etl-report.md
          echo "- Fast test results: See 'fast-test-results' artifact (if applicable)" >> comprehensive-etl-report.md

          echo "üìä Comprehensive report generated: comprehensive-etl-report.md"

      - name: Check for test failures
        run: |
          echo "üîç Checking for test failures..."

          # Check if any test results indicate failures
          failure_count=0

          # Check XML test results for failures
          for results_file in test-results/*/test-results.xml; do
            if [[ -f "$results_file" ]]; then
              failures=$(grep -o 'failures="[0-9]*"' "$results_file" | grep -o '[0-9]*' || echo "0")
              errors=$(grep -o 'errors="[0-9]*"' "$results_file" | grep -o '[0-9]*' || echo "0")

              if [[ $failures -gt 0 || $errors -gt 0 ]]; then
                echo "‚ùå Test failures detected in $results_file: $failures failures, $errors errors"
                failure_count=$((failure_count + failures + errors))
              fi
            fi
          done

          if [[ $failure_count -gt 0 ]]; then
            echo "üí• Total test failures detected: $failure_count"
            echo "failure_detected=true" >> $GITHUB_ENV
            exit 1
          else
            echo "‚úÖ All tests passed successfully"
            echo "failure_detected=false" >> $GITHUB_ENV
          fi

      - name: Upload comprehensive report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-etl-report
          path: comprehensive-etl-report.md
          retention-days: 90

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');

            try {
              const reportContent = fs.readFileSync('comprehensive-etl-report.md', 'utf8');
              const failureDetected = process.env.failure_detected === 'true';

              const emoji = failureDetected ? '‚ùå' : '‚úÖ';
              const status = failureDetected ? 'FAILED' : 'PASSED';

              const comment = `## ${emoji} ETL Pipeline Testing ${status}

              **Test Scope:** ${{ needs.setup.outputs.test-scope }}
              **Platforms:** ${{ needs.setup.outputs.matrix-platforms }}

              <details>
              <summary>üìä View Detailed Report</summary>

              ${reportContent}

              </details>

              ${failureDetected ?
                '‚ö†Ô∏è Some tests failed. Please review the detailed results in the artifacts.' :
                'üéâ All ETL tests passed successfully!'
              }`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('Failed to post PR comment:', error);
            }

  # Job 5: Performance baseline update (scheduled runs only)
  update-baselines:
    name: Update Performance Baselines
    runs-on: macos-14
    needs: [setup, etl-testing]
    if: github.event_name == 'schedule' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Download performance data
        uses: actions/download-artifact@v3
        with:
          name: performance-data-macos-14
          path: performance-data/

      - name: Update performance baselines
        run: |
          echo "üìä Updating performance baselines..."

          # Create baselines directory if it doesn't exist
          mkdir -p performance-baselines

          # Process new performance data
          for perf_file in performance-data/performance-*.json; do
            if [[ -f "$perf_file" ]]; then
              filename=$(basename "$perf_file")
              baseline_file="performance-baselines/$filename"

              # Update baseline with new data
              echo "Updating baseline: $baseline_file"
              cp "$perf_file" "$baseline_file"
            fi
          done

          # Commit updated baselines
          git config user.name "ETL Performance Bot"
          git config user.email "actions@github.com"

          if [[ -n "$(git status --porcelain performance-baselines/)" ]]; then
            git add performance-baselines/
            git commit -m "chore: update ETL performance baselines from scheduled run

            - Updated baselines from workflow run ${{ github.run_id }}
            - Data collected on $(date -u '+%Y-%m-%d %H:%M:%S UTC')
            - Commit: ${{ github.sha }}
            "
            git push

            echo "‚úÖ Performance baselines updated and committed"
          else
            echo "‚ÑπÔ∏è No baseline updates needed"
          fi