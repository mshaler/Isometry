---
phase: 84-cards-and-connections
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/db/schema.sql
  - src/db/migrations/84-cards-connections.sql
autonomous: true

must_haves:
  truths:
    - "cards table exists with 4-type constraint (note, person, event, resource)"
    - "connections table exists with via_card_id column"
    - "All nodes data migrated to cards with type mapping"
    - "All edges data migrated to connections with edge_type -> label"
    - "card_properties table exists (renamed from node_properties)"
    - "cards_fts virtual table exists with sync triggers"
    - "notebook_cards FK updated to reference cards.id"
    - "Backup tables exist for rollback (nodes_backup, edges_backup)"
  artifacts:
    - path: "src/db/schema.sql"
      provides: "New cards/connections schema"
      contains: "CREATE TABLE IF NOT EXISTS cards"
    - path: "src/db/migrations/84-cards-connections.sql"
      provides: "Migration script"
      contains: "INSERT INTO cards"
  key_links:
    - from: "src/db/schema.sql"
      to: "cards table"
      via: "CREATE TABLE cards"
      pattern: "card_type TEXT NOT NULL"
---

<objective>
Create new cards/connections schema and migrate existing data from nodes/edges.

Purpose: Establish the simplified data model foundation (4 card types, via_card_id connections) that all subsequent plans build upon.

Output: New schema.sql with cards/connections tables, migration SQL script, backup tables for rollback safety.
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@CARDS-AND-CONNECTIONS.md
@.planning/phases/84-cards-and-connections/84-RESEARCH.md
@src/db/schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cards and connections tables in schema.sql</name>
  <files>src/db/schema.sql</files>
  <action>
Add new tables to schema.sql BEFORE the existing nodes table (so they're defined first):

1. Create `cards` table with:
   - id TEXT PRIMARY KEY NOT NULL
   - card_type TEXT NOT NULL DEFAULT 'note' CHECK(card_type IN ('note', 'person', 'event', 'resource'))
   - name TEXT NOT NULL
   - content TEXT, summary TEXT
   - LATCH Location: latitude, longitude, location_name (NOT location_address - removed)
   - LATCH Time: created_at, modified_at (with strftime defaults), due_at, completed_at, event_start, event_end
   - LATCH Category: folder, tags, status
   - LATCH Hierarchy: priority INTEGER NOT NULL DEFAULT 0, sort_order INTEGER NOT NULL DEFAULT 0 (NOT importance - removed)
   - Resource-specific: url TEXT, mime_type TEXT
   - Person-specific: is_collective INTEGER NOT NULL DEFAULT 0
   - Source tracking: source, source_id (NOT source_url - removed, use url for Resources)
   - Lifecycle: deleted_at, version INTEGER NOT NULL DEFAULT 1, sync_status TEXT DEFAULT 'pending'

2. Create indexes on cards:
   - idx_cards_type ON cards(card_type) WHERE deleted_at IS NULL
   - idx_cards_folder, idx_cards_created, idx_cards_modified, idx_cards_status, idx_cards_priority, idx_cards_due, idx_cards_event
   - idx_cards_source UNIQUE ON cards(source, source_id) WHERE source IS NOT NULL AND source_id IS NOT NULL

3. Create `connections` table with:
   - id TEXT PRIMARY KEY NOT NULL
   - source_id TEXT NOT NULL REFERENCES cards(id) ON DELETE CASCADE
   - target_id TEXT NOT NULL REFERENCES cards(id) ON DELETE CASCADE
   - via_card_id TEXT REFERENCES cards(id) ON DELETE SET NULL
   - label TEXT (user-provided, schema-on-read)
   - weight REAL NOT NULL DEFAULT 1.0
   - created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%SZ', 'now'))
   - UNIQUE(source_id, target_id, via_card_id)

4. Create indexes on connections:
   - idx_conn_source ON connections(source_id)
   - idx_conn_target ON connections(target_id)
   - idx_conn_via ON connections(via_card_id) WHERE via_card_id IS NOT NULL

5. Create `cards_fts` FTS5 virtual table with triggers:
   - FTS5 on name, content, tags, folder (same as nodes_fts but referencing cards)
   - INSERT trigger: trg_cards_fts_insert
   - DELETE trigger: trg_cards_fts_delete
   - UPDATE trigger: trg_cards_fts_update

6. Add version increment trigger for cards table (same pattern as nodes).

Keep the existing nodes/edges tables intact - they'll be backed up and eventually dropped in Plan 04.
  </action>
  <verify>Run: `grep -c "CREATE TABLE IF NOT EXISTS cards" src/db/schema.sql` returns 1</verify>
  <done>cards and connections tables defined in schema.sql with all indexes and FTS5</done>
</task>

<task type="auto">
  <name>Task 2: Create migration script with data transformation</name>
  <files>src/db/migrations/84-cards-connections.sql</files>
  <action>
Create a new file at src/db/migrations/84-cards-connections.sql with:

1. Backup existing tables:
   ```sql
   CREATE TABLE IF NOT EXISTS nodes_backup AS SELECT * FROM nodes;
   CREATE TABLE IF NOT EXISTS edges_backup AS SELECT * FROM edges;
   ```

2. Migrate nodes -> cards:
   ```sql
   INSERT INTO cards (
     id, card_type, name, content, summary,
     latitude, longitude, location_name,
     created_at, modified_at, due_at, completed_at, event_start, event_end,
     folder, tags, status,
     priority, sort_order,
     url, mime_type, is_collective,
     source, source_id, deleted_at, version, sync_status
   )
   SELECT
     id,
     CASE
       WHEN node_type = 'contact' THEN 'person'
       WHEN node_type IN ('task', 'project', 'notebook') THEN 'note'
       WHEN node_type = 'event' THEN 'event'
       WHEN node_type = 'resource' THEN 'resource'
       ELSE 'note'
     END as card_type,
     name, content, summary,
     latitude, longitude, location_name,
     created_at, modified_at, due_at, completed_at, event_start, event_end,
     folder, tags, status,
     priority, sort_order,
     source_url as url,  -- source_url becomes url for Resources
     NULL as mime_type,
     0 as is_collective,
     source, source_id, deleted_at, version,
     'pending' as sync_status
   FROM nodes
   WHERE NOT EXISTS (SELECT 1 FROM cards WHERE cards.id = nodes.id);
   ```

3. Migrate edges -> connections:
   ```sql
   INSERT INTO connections (id, source_id, target_id, via_card_id, label, weight, created_at)
   SELECT
     id, source_id, target_id, NULL as via_card_id,
     LOWER(COALESCE(label, edge_type)) as label,  -- edge_type becomes label, lowercase
     weight, created_at
   FROM edges
   WHERE NOT EXISTS (SELECT 1 FROM connections WHERE connections.id = edges.id);
   ```

4. Rename node_properties -> card_properties:
   ```sql
   ALTER TABLE node_properties RENAME TO card_properties;
   ```

   Note: SQLite doesn't support renaming column in same statement, but FK reference updates automatically with table rename.

5. Update notebook_cards FK (create new table with correct FK):
   ```sql
   -- SQLite doesn't support ALTER COLUMN, so we recreate with correct FK
   -- For now, just update the data - the FK constraint references by id, not column name
   -- The existing node_id column values are valid card ids after migration
   ```

6. Rebuild cards_fts index:
   ```sql
   INSERT INTO cards_fts(cards_fts) VALUES('rebuild');
   ```
  </action>
  <verify>File exists at src/db/migrations/84-cards-connections.sql with INSERT INTO cards SELECT FROM nodes</verify>
  <done>Migration script ready to transform nodes->cards and edges->connections with backups</done>
</task>

<task type="auto">
  <name>Task 3: Write migration test to verify data integrity</name>
  <files>src/db/__tests__/cards-migration.test.ts</files>
  <action>
Create test file at src/db/__tests__/cards-migration.test.ts:

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import initSqlJs, { Database } from 'sql.js';
import { readFileSync } from 'fs';
import { join } from 'path';

describe('Cards & Connections Migration', () => {
  let db: Database;

  beforeEach(async () => {
    const SQL = await initSqlJs();
    db = new SQL.Database();

    // Load old schema (just nodes/edges tables)
    const oldSchema = `
      CREATE TABLE nodes (
        id TEXT PRIMARY KEY,
        node_type TEXT NOT NULL DEFAULT 'note',
        name TEXT NOT NULL,
        content TEXT,
        summary TEXT,
        latitude REAL,
        longitude REAL,
        location_name TEXT,
        location_address TEXT,
        created_at TEXT,
        modified_at TEXT,
        due_at TEXT,
        completed_at TEXT,
        event_start TEXT,
        event_end TEXT,
        folder TEXT,
        tags TEXT,
        status TEXT,
        priority INTEGER DEFAULT 0,
        importance INTEGER DEFAULT 0,
        sort_order INTEGER DEFAULT 0,
        grid_x REAL DEFAULT 0,
        grid_y REAL DEFAULT 0,
        source TEXT,
        source_id TEXT,
        source_url TEXT,
        deleted_at TEXT,
        version INTEGER DEFAULT 1
      );

      CREATE TABLE edges (
        id TEXT PRIMARY KEY,
        edge_type TEXT NOT NULL,
        source_id TEXT NOT NULL,
        target_id TEXT NOT NULL,
        label TEXT,
        weight REAL DEFAULT 1.0,
        directed INTEGER DEFAULT 1,
        sequence_order INTEGER,
        channel TEXT,
        timestamp TEXT,
        subject TEXT,
        created_at TEXT
      );
    `;
    db.run(oldSchema);

    // Insert test data
    db.run(`INSERT INTO nodes VALUES
      ('n1', 'note', 'Test Note', 'Content', 'Summary', NULL, NULL, NULL, NULL,
       '2024-01-01', '2024-01-02', NULL, NULL, NULL, NULL, 'work', '["tag1"]', 'active',
       5, 3, 0, 0, 0, 'test', 'src1', 'http://example.com', NULL, 1),
      ('n2', 'contact', 'John Doe', NULL, NULL, 40.7, -74.0, 'NYC', '123 Main St',
       '2024-01-01', '2024-01-02', NULL, NULL, NULL, NULL, 'contacts', NULL, NULL,
       0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, 1),
      ('n3', 'event', 'Meeting', 'Agenda', NULL, NULL, NULL, NULL, NULL,
       '2024-01-01', '2024-01-02', NULL, NULL, '2024-02-01T10:00', '2024-02-01T11:00',
       'work', NULL, NULL, 3, 0, 0, 0, 0, 'calendar', 'evt1', NULL, NULL, 1)`);

    db.run(`INSERT INTO edges VALUES
      ('e1', 'LINK', 'n1', 'n2', NULL, 1.0, 1, NULL, NULL, NULL, NULL, '2024-01-01'),
      ('e2', 'NEST', 'n1', 'n3', 'contains', 0.8, 1, 1, 'email', '2024-01-15', 'topic', '2024-01-01')`);
  });

  it('should migrate nodes to cards with type mapping', () => {
    // Create cards table
    const cardsSchema = readFileSync(join(__dirname, '../../schema.sql'), 'utf-8');
    // Extract just the cards table definition... (simplified for test)

    db.run(`
      CREATE TABLE cards (
        id TEXT PRIMARY KEY,
        card_type TEXT NOT NULL DEFAULT 'note' CHECK(card_type IN ('note', 'person', 'event', 'resource')),
        name TEXT NOT NULL,
        content TEXT,
        summary TEXT,
        latitude REAL,
        longitude REAL,
        location_name TEXT,
        created_at TEXT,
        modified_at TEXT,
        due_at TEXT,
        completed_at TEXT,
        event_start TEXT,
        event_end TEXT,
        folder TEXT,
        tags TEXT,
        status TEXT,
        priority INTEGER NOT NULL DEFAULT 0,
        sort_order INTEGER NOT NULL DEFAULT 0,
        url TEXT,
        mime_type TEXT,
        is_collective INTEGER NOT NULL DEFAULT 0,
        source TEXT,
        source_id TEXT,
        deleted_at TEXT,
        version INTEGER NOT NULL DEFAULT 1,
        sync_status TEXT DEFAULT 'pending'
      )
    `);

    // Run migration
    db.run(`
      INSERT INTO cards (id, card_type, name, content, summary,
        latitude, longitude, location_name,
        created_at, modified_at, due_at, completed_at, event_start, event_end,
        folder, tags, status, priority, sort_order, url, source, source_id, version)
      SELECT id,
        CASE
          WHEN node_type = 'contact' THEN 'person'
          WHEN node_type = 'event' THEN 'event'
          WHEN node_type = 'resource' THEN 'resource'
          ELSE 'note'
        END,
        name, content, summary,
        latitude, longitude, location_name,
        created_at, modified_at, due_at, completed_at, event_start, event_end,
        folder, tags, status, priority, sort_order, source_url, source, source_id, version
      FROM nodes
    `);

    const cards = db.exec('SELECT id, card_type, name FROM cards ORDER BY id');
    expect(cards[0].values).toHaveLength(3);
    expect(cards[0].values[0]).toEqual(['n1', 'note', 'Test Note']);
    expect(cards[0].values[1]).toEqual(['n2', 'person', 'John Doe']);
    expect(cards[0].values[2]).toEqual(['n3', 'event', 'Meeting']);
  });

  it('should migrate edges to connections with lowercase labels', () => {
    db.run(`
      CREATE TABLE connections (
        id TEXT PRIMARY KEY,
        source_id TEXT NOT NULL,
        target_id TEXT NOT NULL,
        via_card_id TEXT,
        label TEXT,
        weight REAL NOT NULL DEFAULT 1.0,
        created_at TEXT
      )
    `);

    db.run(`
      INSERT INTO connections (id, source_id, target_id, label, weight, created_at)
      SELECT id, source_id, target_id,
        LOWER(COALESCE(label, edge_type)),
        weight, created_at
      FROM edges
    `);

    const conns = db.exec('SELECT id, label FROM connections ORDER BY id');
    expect(conns[0].values).toHaveLength(2);
    expect(conns[0].values[0]).toEqual(['e1', 'link']);  // edge_type LINK -> label 'link'
    expect(conns[0].values[1]).toEqual(['e2', 'contains']); // existing label preserved
  });

  it('should remove deprecated columns', () => {
    // Verify cards table doesn't have: location_address, importance, grid_x, grid_y, source_url
    const pragmaResult = db.exec("PRAGMA table_info(cards)");
    // After creating the table above, verify structure
    const cardsCols = db.exec("SELECT name FROM pragma_table_info('cards')");
    const colNames = cardsCols[0]?.values.map(v => v[0]) || [];

    expect(colNames).not.toContain('location_address');
    expect(colNames).not.toContain('importance');
    expect(colNames).not.toContain('grid_x');
    expect(colNames).not.toContain('grid_y');
    expect(colNames).not.toContain('source_url');

    // Verify new columns exist
    expect(colNames).toContain('url');
    expect(colNames).toContain('mime_type');
    expect(colNames).toContain('is_collective');
    expect(colNames).toContain('sync_status');
  });
});
```

Run the test to verify migration logic works correctly.
  </action>
  <verify>npm run test -- src/db/__tests__/cards-migration.test.ts passes</verify>
  <done>Migration test validates type mapping, column removal, and label conversion</done>
</task>

</tasks>

<verification>
1. `grep "CREATE TABLE IF NOT EXISTS cards" src/db/schema.sql` shows cards table definition
2. `grep "card_type.*CHECK" src/db/schema.sql` shows 4-type constraint
3. `grep "via_card_id" src/db/schema.sql` shows connections table has bridge card FK
4. `ls src/db/migrations/84-cards-connections.sql` confirms migration script exists
5. `npm run test -- src/db/__tests__/cards-migration.test.ts` passes
</verification>

<success_criteria>
- cards table created with card_type CHECK constraint for 4 types
- connections table created with via_card_id column
- Migration script transforms node_type -> card_type correctly
- Migration script converts edge_type -> lowercase label
- Deprecated columns (location_address, importance, grid_x/y, source_url) not in cards
- New columns (url, mime_type, is_collective, sync_status) present in cards
- FTS5 cards_fts table defined with sync triggers
- Tests pass verifying migration logic
</success_criteria>

<output>
After completion, create `.planning/phases/84-cards-and-connections/84-01-SUMMARY.md`
</output>
