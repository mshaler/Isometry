---
phase: 69-file-importers
plan: 04
type: tdd
wave: 2
depends_on: []
files_modified:
  - src/etl/importers/HtmlImporter.ts
  - src/etl/__tests__/HtmlImporter.test.ts
autonomous: true

must_haves:
  truths:
    - "HtmlImporter extracts content from HTML files"
    - "Title extracted from <title> or first <h1>"
    - "Meta tags mapped to LATCH fields"
    - "Main content extracted from semantic elements"
  artifacts:
    - path: "src/etl/importers/HtmlImporter.ts"
      provides: "HTML importer extending BaseImporter"
      exports: ["HtmlImporter"]
    - path: "src/etl/__tests__/HtmlImporter.test.ts"
      provides: "TDD tests for HTML import"
      min_lines: 70
  key_links:
    - from: "src/etl/importers/HtmlImporter.ts"
      to: "src/etl/importers/BaseImporter.ts"
      via: "extends BaseImporter"
      pattern: "extends BaseImporter"
    - from: "src/etl/importers/HtmlImporter.ts"
      to: "DOMParser"
      via: "native browser API"
      pattern: "new DOMParser"
---

<objective>
Implement HtmlImporter for .html and .htm file import using TDD.

Purpose: HTML uses native DOMParser (zero dependencies), extracts semantic content and metadata, and demonstrates proper content sanitization patterns.

Output: Working HtmlImporter that extracts title, meta tags, and main content from HTML files.
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/68-import-coordinator/68-01-SUMMARY.md

# Foundation from Phase 68
@src/etl/importers/BaseImporter.ts
@src/etl/types/canonical.ts
@src/etl/id-generation/deterministic.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create failing tests for HtmlImporter</name>
  <files>src/etl/__tests__/HtmlImporter.test.ts</files>
  <action>
1. Create HtmlImporter.test.ts with failing tests:

```typescript
/**
 * @vitest-environment jsdom
 */
import { HtmlImporter } from '../importers/HtmlImporter';
import { CanonicalNodeSchema } from '../types/canonical';
import { FileSource } from '../importers/BaseImporter';

describe('HtmlImporter', () => {
  let importer: HtmlImporter;

  beforeEach(() => {
    importer = new HtmlImporter();
  });

  describe('title extraction', () => {
    it('should extract title from <title> tag', async () => {
      const html = `<!DOCTYPE html>
<html>
<head><title>Page Title</title></head>
<body><p>Content</p></body>
</html>`;

      const nodes = await importer.import({
        filename: 'page.html',
        content: html,
      });

      expect(nodes).toHaveLength(1);
      expect(nodes[0].name).toBe('Page Title');
    });

    it('should extract title from <h1> when no <title>', async () => {
      const html = `<html>
<body><h1>Heading Title</h1><p>Content</p></body>
</html>`;

      const nodes = await importer.import({
        filename: 'no-title.html',
        content: html,
      });

      expect(nodes[0].name).toBe('Heading Title');
    });

    it('should fallback to filename when no title found', async () => {
      const html = `<html><body><p>Just content</p></body></html>`;

      const nodes = await importer.import({
        filename: 'untitled.html',
        content: html,
      });

      expect(nodes[0].name).toBe('untitled');
    });
  });

  describe('meta tag extraction', () => {
    it('should extract description from meta tag', async () => {
      const html = `<html>
<head>
  <title>Test</title>
  <meta name="description" content="This is a page description">
</head>
<body><p>Content</p></body>
</html>`;

      const nodes = await importer.import({
        filename: 'meta.html',
        content: html,
      });

      expect(nodes[0].summary).toBe('This is a page description');
    });

    it('should extract keywords as tags', async () => {
      const html = `<html>
<head>
  <title>Test</title>
  <meta name="keywords" content="typescript, react, testing">
</head>
<body><p>Content</p></body>
</html>`;

      const nodes = await importer.import({
        filename: 'keywords.html',
        content: html,
      });

      expect(nodes[0].tags).toEqual(['typescript', 'react', 'testing']);
    });

    it('should extract author', async () => {
      const html = `<html>
<head>
  <title>Test</title>
  <meta name="author" content="John Doe">
</head>
<body><p>Content</p></body>
</html>`;

      const nodes = await importer.import({
        filename: 'author.html',
        content: html,
      });

      expect(nodes[0].properties).toHaveProperty('author', 'John Doe');
    });
  });

  describe('content extraction', () => {
    it('should extract content from <main> element', async () => {
      const html = `<html>
<head><title>Test</title></head>
<body>
  <nav>Navigation</nav>
  <main>
    <h1>Main Content</h1>
    <p>Important paragraph</p>
  </main>
  <footer>Footer</footer>
</body>
</html>`;

      const nodes = await importer.import({
        filename: 'main.html',
        content: html,
      });

      expect(nodes[0].content).toContain('Main Content');
      expect(nodes[0].content).toContain('Important paragraph');
      expect(nodes[0].content).not.toContain('Navigation');
      expect(nodes[0].content).not.toContain('Footer');
    });

    it('should extract content from <article> element', async () => {
      const html = `<html>
<body>
  <article>
    <h1>Article Title</h1>
    <p>Article content</p>
  </article>
</body>
</html>`;

      const nodes = await importer.import({
        filename: 'article.html',
        content: html,
      });

      expect(nodes[0].content).toContain('Article content');
    });

    it('should fallback to <body> content', async () => {
      const html = `<html>
<head><title>Test</title></head>
<body>
  <div>Some content here</div>
</body>
</html>`;

      const nodes = await importer.import({
        filename: 'body.html',
        content: html,
      });

      expect(nodes[0].content).toContain('Some content here');
    });
  });

  describe('edge cases', () => {
    it('should handle empty HTML', async () => {
      const nodes = await importer.import({
        filename: 'empty.html',
        content: '',
      });

      expect(nodes).toHaveLength(1);
      expect(nodes[0].name).toBe('empty');
    });

    it('should handle malformed HTML gracefully', async () => {
      const html = `<html><body><p>Unclosed paragraph`;

      const nodes = await importer.import({
        filename: 'malformed.html',
        content: html,
      });

      expect(nodes).toHaveLength(1);
      expect(nodes[0].content).toContain('Unclosed paragraph');
    });

    it('should preserve HTML in content field', async () => {
      const html = `<html>
<body>
  <main>
    <p><strong>Bold</strong> and <em>italic</em></p>
  </main>
</body>
</html>`;

      const nodes = await importer.import({
        filename: 'formatted.html',
        content: html,
      });

      expect(nodes[0].content).toContain('<strong>');
      expect(nodes[0].content).toContain('<em>');
    });
  });

  describe('deterministic IDs', () => {
    it('should generate deterministic sourceId', async () => {
      const html = `<html><head><title>Test</title></head><body>Content</body></html>`;
      const source: FileSource = { filename: 'test.html', content: html };

      const nodes1 = await importer.import(source);
      const nodes2 = await importer.import(source);

      expect(nodes1[0].sourceId).toBe(nodes2[0].sourceId);
      expect(nodes1[0].sourceId).toMatch(/^html-importer-/);
    });
  });

  describe('validation', () => {
    it('should produce valid CanonicalNode', async () => {
      const html = `<html>
<head><title>Valid Page</title></head>
<body><main><p>Content</p></main></body>
</html>`;

      const nodes = await importer.import({
        filename: 'valid.html',
        content: html,
      });

      expect(() => CanonicalNodeSchema.parse(nodes[0])).not.toThrow();
    });
  });
});
```

2. Run tests to verify they fail:
   ```bash
   npm run test -- --run src/etl/__tests__/HtmlImporter.test.ts
   ```

Note: Tests use `@vitest-environment jsdom` for DOMParser support.
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/HtmlImporter.test.ts` runs and all tests FAIL
    - Tests cover title, meta, content extraction, edge cases
  </verify>
  <done>Tests written for HtmlImporter covering extraction patterns. All tests fail (RED phase).</done>
</task>

<task type="auto">
  <name>Task 2: Implement HtmlImporter to pass tests</name>
  <files>src/etl/importers/HtmlImporter.ts</files>
  <action>
1. Create HtmlImporter:

```typescript
/**
 * HTML Importer for Isometry ETL
 *
 * Parses .html and .htm files using native DOMParser.
 * Extracts semantic content from <main>, <article>, or <body>.
 * Maps meta tags to LATCH fields.
 */

import { v4 as uuidv4 } from 'uuid';
import { BaseImporter, FileSource } from './BaseImporter';
import { CanonicalNode } from '../types/canonical';
import { generateDeterministicSourceId } from '../id-generation/deterministic';

interface ParsedHtml {
  doc: Document;
  title: string | null;
  description: string | null;
  keywords: string[];
  author: string | null;
  mainContent: string;
  textContent: string;
  filename: string;
}

export class HtmlImporter extends BaseImporter {
  protected async parse(source: FileSource): Promise<unknown> {
    const parser = new DOMParser();
    const doc = parser.parseFromString(source.content || '<html></html>', 'text/html');

    // Extract title
    const titleTag = doc.querySelector('title');
    const h1 = doc.querySelector('h1');
    const title = titleTag?.textContent?.trim() || h1?.textContent?.trim() || null;

    // Extract meta tags
    const description = doc.querySelector('meta[name="description"]')?.getAttribute('content') || null;
    const keywordsStr = doc.querySelector('meta[name="keywords"]')?.getAttribute('content') || '';
    const keywords = keywordsStr
      ? keywordsStr.split(',').map(k => k.trim()).filter(Boolean)
      : [];
    const author = doc.querySelector('meta[name="author"]')?.getAttribute('content') || null;

    // Extract main content (prefer semantic elements)
    const mainElement = doc.querySelector('main') || doc.querySelector('article') || doc.body;
    const mainContent = mainElement?.innerHTML || '';
    const textContent = mainElement?.textContent || '';

    return {
      doc,
      title,
      description,
      keywords,
      author,
      mainContent,
      textContent,
      filename: source.filename,
    };
  }

  protected async transform(data: unknown): Promise<CanonicalNode[]> {
    const {
      title,
      description,
      keywords,
      author,
      mainContent,
      textContent,
      filename,
    } = data as ParsedHtml;

    const now = new Date().toISOString();

    // Derive name from title, h1, or filename
    const name = title || this.extractFilename(filename);

    const sourceId = generateDeterministicSourceId(
      filename,
      { title, description, contentHash: this.hashContent(textContent) },
      'html-importer'
    );

    const node: CanonicalNode = {
      id: uuidv4(),
      sourceId,
      source: 'html-importer',
      nodeType: 'note',
      name,
      content: mainContent,
      summary: description || textContent.slice(0, 200).trim() || null,

      // LATCH: Location
      latitude: null,
      longitude: null,
      locationName: null,
      locationAddress: null,

      // LATCH: Time
      createdAt: now,
      modifiedAt: now,
      dueAt: null,
      completedAt: null,
      eventStart: null,
      eventEnd: null,

      // LATCH: Category
      folder: null,
      tags: keywords,
      status: null,

      // LATCH: Hierarchy
      priority: 0,
      importance: 0,
      sortOrder: 0,

      // Grid
      gridX: 0,
      gridY: 0,

      // Provenance
      sourceUrl: null,
      deletedAt: null,
      version: 1,

      // Extended properties
      properties: {
        originalFormat: 'html',
        wordCount: textContent.split(/\s+/).filter(Boolean).length,
        ...(author ? { author } : {}),
      },
    };

    return [node];
  }

  private extractFilename(filepath: string): string {
    // Extract filename without extension
    const parts = filepath.split(/[/\\]/);
    const filename = parts[parts.length - 1] || 'untitled';
    return filename.replace(/\.(html?|htm)$/i, '');
  }

  private hashContent(text: string): string {
    // Simple hash for deterministic ID
    let hash = 0;
    for (let i = 0; i < Math.min(text.length, 1000); i++) {
      hash = ((hash << 5) - hash) + text.charCodeAt(i);
      hash = hash & hash;
    }
    return Math.abs(hash).toString(16);
  }
}
```

2. Run tests:
   ```bash
   npm run test -- --run src/etl/__tests__/HtmlImporter.test.ts
   ```

3. Run typecheck:
   ```bash
   npm run check:types
   ```
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/HtmlImporter.test.ts` passes all tests (GREEN)
    - `npm run check:types` has zero errors
  </verify>
  <done>HtmlImporter implemented and all tests pass.</done>
</task>

<task type="auto">
  <name>Task 3: Add integration test</name>
  <files>src/etl/__tests__/HtmlImporter.test.ts</files>
  <action>
1. Add integration test:

```typescript
describe('HtmlImporter integration', () => {
  it('should work with ImportCoordinator', async () => {
    const { ImportCoordinator } = await import('../coordinator/ImportCoordinator');
    const coordinator = new ImportCoordinator();
    coordinator.registerImporter(['.html', '.htm'], new HtmlImporter());

    const html = `<html>
<head><title>Integration Test</title></head>
<body><main><p>Test content</p></main></body>
</html>`;

    const nodes = await coordinator.importFile({
      filename: 'integration.html',
      content: html,
    });

    expect(nodes).toHaveLength(1);
    expect(nodes[0].name).toBe('Integration Test');
    expect(() => CanonicalNodeSchema.parse(nodes[0])).not.toThrow();
  });
});
```

2. Run full test suite:
   ```bash
   npm run test -- --run
   ```
  </action>
  <verify>
    - All HtmlImporter tests pass
    - Integration with ImportCoordinator works
  </verify>
  <done>HtmlImporter complete with integration test.</done>
</task>

</tasks>

<verification>
1. `npm run test -- --run src/etl/__tests__/HtmlImporter.test.ts` - all tests pass
2. `npm run check:types` - zero TypeScript errors
3. Title extracted from <title> or <h1>
4. Meta tags mapped to LATCH fields
5. Semantic content extraction (<main>, <article>, <body>)
</verification>

<success_criteria>
1. HtmlImporter parses HTML using native DOMParser
2. Title extracted from <title> or fallback to <h1>
3. Meta tags (description, keywords, author) mapped
4. Main content extracted from semantic elements
5. Malformed HTML handled gracefully
6. All tests pass with TDD cycle
</success_criteria>

<output>
After completion, create `.planning/phases/69-file-importers/69-04-SUMMARY.md`
</output>
