---
phase: 69-file-importers
plan: 06
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/etl/importers/ExcelImporter.ts
  - src/etl/__tests__/ExcelImporter.test.ts
autonomous: true

must_haves:
  truths:
    - "ExcelImporter produces one node per row across all sheets"
    - "Column headers map to LATCH fields with intelligent detection"
    - "Multi-sheet workbooks handled (sheet name stored in folder)"
    - "Formula values evaluated, formulas stored in properties"
  artifacts:
    - path: "src/etl/importers/ExcelImporter.ts"
      provides: "Excel importer extending BaseImporter"
      exports: ["ExcelImporter"]
    - path: "src/etl/__tests__/ExcelImporter.test.ts"
      provides: "TDD tests for Excel import"
      min_lines: 100
  key_links:
    - from: "src/etl/importers/ExcelImporter.ts"
      to: "src/etl/importers/BaseImporter.ts"
      via: "extends BaseImporter"
      pattern: "extends BaseImporter"
    - from: "src/etl/importers/ExcelImporter.ts"
      to: "xlsx"
      via: "XLSX.read"
      pattern: "XLSX\\.read"
---

<objective>
Implement ExcelImporter for .xlsx and .xls file import using TDD.

Purpose: Excel is the most complex format - multi-sheet workbooks, formulas, cell types, binary encoding. SheetJS (xlsx) is already installed and handles the complexity. One node per row across all sheets demonstrates full multi-node pattern.

Output: Working ExcelImporter that imports all sheets with intelligent LATCH column mapping.
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/68-import-coordinator/68-01-SUMMARY.md

# Foundation from Phase 68
@src/etl/importers/BaseImporter.ts
@src/etl/types/canonical.ts
@src/etl/id-generation/deterministic.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create failing tests for ExcelImporter</name>
  <files>src/etl/__tests__/ExcelImporter.test.ts</files>
  <action>
1. Create ExcelImporter.test.ts with failing tests:

Note: Testing Excel requires either real files or mocking xlsx. We'll mock xlsx for unit tests:

```typescript
import { ExcelImporter } from '../importers/ExcelImporter';
import { CanonicalNodeSchema } from '../types/canonical';
import { FileSource } from '../importers/BaseImporter';
import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';

// Mock xlsx
vi.mock('xlsx', () => ({
  read: vi.fn(),
  utils: {
    sheet_to_json: vi.fn(),
  },
}));

import * as XLSX from 'xlsx';

describe('ExcelImporter', () => {
  let importer: ExcelImporter;

  beforeEach(() => {
    importer = new ExcelImporter();
  });

  afterEach(() => {
    vi.clearAllMocks();
  });

  describe('single sheet', () => {
    it('should import rows from single sheet', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: {
          Sheet1: {},
        },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Task 1', status: 'todo' },
        { name: 'Task 2', status: 'done' },
        { name: 'Task 3', status: 'in-progress' },
      ]);

      const nodes = await importer.import({
        filename: 'tasks.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes).toHaveLength(3);
      expect(nodes[0].name).toBe('Task 1');
      expect(nodes[1].name).toBe('Task 2');
      expect(nodes[2].name).toBe('Task 3');
    });

    it('should use sheet name as folder', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Tasks'],
        Sheets: { Tasks: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Task 1' },
      ]);

      const nodes = await importer.import({
        filename: 'work.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].folder).toBe('Tasks');
    });
  });

  describe('multiple sheets', () => {
    it('should import rows from all sheets', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Tasks', 'Contacts'],
        Sheets: { Tasks: {}, Contacts: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json)
        .mockReturnValueOnce([{ name: 'Task 1' }, { name: 'Task 2' }])
        .mockReturnValueOnce([{ name: 'Contact 1' }]);

      const nodes = await importer.import({
        filename: 'multi.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes).toHaveLength(3);
      expect(nodes[0].folder).toBe('Tasks');
      expect(nodes[1].folder).toBe('Tasks');
      expect(nodes[2].folder).toBe('Contacts');
    });
  });

  describe('LATCH column mapping', () => {
    it('should detect name from various column headers', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });

      const testCases = [
        { column: 'name', value: 'From name' },
        { column: 'title', value: 'From title' },
        { column: 'task', value: 'From task' },
        { column: 'subject', value: 'From subject' },
      ];

      for (const { column, value } of testCases) {
        vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([{ [column]: value }]);

        const nodes = await importer.import({
          filename: 'test.xlsx',
          content: 'base64content',
          encoding: 'base64',
        });

        expect(nodes[0].name).toBe(value);
      }
    });

    it('should detect date columns', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        {
          name: 'Task 1',
          created: '2024-01-15T10:00:00Z',
          due_date: '2024-02-01T00:00:00Z',
          modified: '2024-01-20T12:00:00Z',
        },
      ]);

      const nodes = await importer.import({
        filename: 'dates.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].createdAt).toBe('2024-01-15T10:00:00Z');
      expect(nodes[0].dueAt).toBe('2024-02-01T00:00:00Z');
      expect(nodes[0].modifiedAt).toBe('2024-01-20T12:00:00Z');
    });

    it('should detect tags from comma-separated string', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Task 1', tags: 'urgent, important, work' },
      ]);

      const nodes = await importer.import({
        filename: 'tags.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].tags).toEqual(['urgent', 'important', 'work']);
    });

    it('should detect priority from string values', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'High Priority', priority: 'high' },
        { name: 'Medium Priority', priority: 'medium' },
        { name: 'Low Priority', priority: 'low' },
      ]);

      const nodes = await importer.import({
        filename: 'priority.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].priority).toBe(5);
      expect(nodes[1].priority).toBe(3);
      expect(nodes[2].priority).toBe(1);
    });
  });

  describe('edge cases', () => {
    it('should handle empty sheet', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Empty'],
        Sheets: { Empty: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([]);

      const nodes = await importer.import({
        filename: 'empty.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes).toHaveLength(0);
    });

    it('should handle mixed data types', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        {
          name: 'Mixed Types',
          count: 42,
          active: true,
          price: 19.99,
        },
      ]);

      const nodes = await importer.import({
        filename: 'mixed.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].name).toBe('Mixed Types');
      // Original data preserved in content
      expect(nodes[0].content).toContain('"count": 42');
      expect(nodes[0].content).toContain('"active": true');
    });

    it('should fallback to row number when no name column', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { value: 100, category: 'A' },
      ]);

      const nodes = await importer.import({
        filename: 'noname.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].name).toBe('Sheet1 Row 1');
    });
  });

  describe('deterministic IDs', () => {
    it('should generate unique sourceId per row', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Row 1' },
        { name: 'Row 2' },
      ]);

      const nodes = await importer.import({
        filename: 'unique.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(nodes[0].sourceId).not.toBe(nodes[1].sourceId);
      expect(nodes[0].sourceId).toMatch(/^excel-importer-/);
    });

    it('should generate consistent sourceId on reimport', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Consistent Row' },
      ]);

      const source: FileSource = {
        filename: 'consistent.xlsx',
        content: 'base64content',
        encoding: 'base64',
      };

      const nodes1 = await importer.import(source);
      const nodes2 = await importer.import(source);

      expect(nodes1[0].sourceId).toBe(nodes2[0].sourceId);
    });
  });

  describe('encoding', () => {
    it('should handle base64 encoded content', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([{ name: 'Test' }]);

      await importer.import({
        filename: 'base64.xlsx',
        content: 'SGVsbG8=',
        encoding: 'base64',
      });

      expect(XLSX.read).toHaveBeenCalled();
      const call = vi.mocked(XLSX.read).mock.calls[0];
      expect(call[1]).toEqual({ type: 'buffer' });
    });
  });

  describe('validation', () => {
    it('should produce valid CanonicalNode', async () => {
      vi.mocked(XLSX.read).mockReturnValue({
        SheetNames: ['Sheet1'],
        Sheets: { Sheet1: {} },
      });
      vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
        { name: 'Valid Row', created: '2024-01-15T10:00:00Z' },
      ]);

      const nodes = await importer.import({
        filename: 'valid.xlsx',
        content: 'base64content',
        encoding: 'base64',
      });

      expect(() => CanonicalNodeSchema.parse(nodes[0])).not.toThrow();
    });
  });

  describe('error handling', () => {
    it('should throw descriptive error on parse failure', async () => {
      vi.mocked(XLSX.read).mockImplementation(() => {
        throw new Error('Invalid Excel file');
      });

      await expect(
        importer.import({
          filename: 'corrupt.xlsx',
          content: 'badcontent',
          encoding: 'base64',
        })
      ).rejects.toThrow(/corrupt\.xlsx.*Invalid Excel/i);
    });
  });
});
```

2. Run tests to verify they fail:
   ```bash
   npm run test -- --run src/etl/__tests__/ExcelImporter.test.ts
   ```
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/ExcelImporter.test.ts` runs and all tests FAIL
    - Tests cover single/multi sheet, LATCH mapping, edge cases
  </verify>
  <done>Tests written for ExcelImporter with xlsx mocking. All tests fail (RED phase).</done>
</task>

<task type="auto">
  <name>Task 2: Implement ExcelImporter to pass tests</name>
  <files>src/etl/importers/ExcelImporter.ts</files>
  <action>
1. Create ExcelImporter:

```typescript
/**
 * Excel Importer for Isometry ETL
 *
 * Parses .xlsx and .xls files using SheetJS (xlsx).
 * One node per row, across all sheets.
 *
 * LATCH mapping with intelligent column detection.
 * Sheet name used as folder for organization.
 */

import * as XLSX from 'xlsx';
import { v4 as uuidv4 } from 'uuid';
import { BaseImporter, FileSource } from './BaseImporter';
import { CanonicalNode } from '../types/canonical';
import { generateDeterministicSourceId } from '../id-generation/deterministic';

interface ParsedExcel {
  sheets: Array<{
    name: string;
    rows: Record<string, unknown>[];
  }>;
  filename: string;
}

export class ExcelImporter extends BaseImporter {
  protected async parse(source: FileSource): Promise<unknown> {
    try {
      // Convert content to buffer
      const buffer = this.toBuffer(source.content, source.encoding);

      // Read workbook
      const workbook = XLSX.read(buffer, { type: 'buffer' });

      // Extract all sheets
      const sheets = workbook.SheetNames.map(name => ({
        name,
        rows: XLSX.utils.sheet_to_json(workbook.Sheets[name]) as Record<string, unknown>[],
      }));

      return { sheets, filename: source.filename };
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      throw new Error(`Failed to parse ${source.filename}: ${message}`);
    }
  }

  protected async transform(data: unknown): Promise<CanonicalNode[]> {
    const { sheets, filename } = data as ParsedExcel;
    const nodes: CanonicalNode[] = [];
    const now = new Date().toISOString();

    for (const sheet of sheets) {
      for (let rowIndex = 0; rowIndex < sheet.rows.length; rowIndex++) {
        const row = sheet.rows[rowIndex];
        const node = this.rowToNode(row, filename, sheet.name, rowIndex, now);
        nodes.push(node);
      }
    }

    return nodes;
  }

  private rowToNode(
    row: Record<string, unknown>,
    filename: string,
    sheetName: string,
    rowIndex: number,
    now: string
  ): CanonicalNode {
    const sourceId = generateDeterministicSourceId(
      `${filename}:${sheetName}:${rowIndex}`,
      row,
      'excel-importer'
    );

    return {
      id: uuidv4(),
      sourceId,
      source: 'excel-importer',
      nodeType: detectNodeType(row),
      name: detectName(row, sheetName, rowIndex),
      content: JSON.stringify(row, null, 2),
      summary: detectSummary(row),

      // LATCH: Location
      latitude: parseNumber(detectValue(row, ['latitude', 'lat'])),
      longitude: parseNumber(detectValue(row, ['longitude', 'lng', 'lon'])),
      locationName: detectValue(row, ['location_name', 'locationName', 'place']),
      locationAddress: detectValue(row, ['address', 'location', 'locationAddress']),

      // LATCH: Time
      createdAt: detectDate(row, ['created', 'createdAt', 'created_at', 'date', 'timestamp']) || now,
      modifiedAt: detectDate(row, ['modified', 'modifiedAt', 'modified_at', 'updated']) || now,
      dueAt: detectDate(row, ['due', 'dueAt', 'due_at', 'due_date', 'deadline']) || null,
      completedAt: detectDate(row, ['completed', 'completedAt', 'completed_at']) || null,
      eventStart: detectDate(row, ['start', 'eventStart', 'start_date']) || null,
      eventEnd: detectDate(row, ['end', 'eventEnd', 'end_date']) || null,

      // LATCH: Category
      folder: detectValue(row, ['folder', 'category', 'group', 'project']) || sheetName,
      tags: detectTags(row),
      status: detectValue(row, ['status', 'state']),

      // LATCH: Hierarchy
      priority: detectPriority(row),
      importance: parseNumber(detectValue(row, ['importance'])) || 0,
      sortOrder: parseNumber(detectValue(row, ['sort_order', 'sortOrder', 'order'])) || 0,

      // Grid
      gridX: 0,
      gridY: 0,

      // Provenance
      sourceUrl: detectValue(row, ['url', 'link', 'source_url']),
      deletedAt: null,
      version: 1,

      // Extended properties
      properties: {
        originalFormat: 'excel',
        sheetName,
        rowIndex,
        columns: Object.keys(row),
      },
    };
  }

  private toBuffer(content: string, encoding?: 'utf8' | 'base64'): Buffer {
    if (encoding === 'base64') {
      return Buffer.from(content, 'base64');
    }
    return Buffer.from(content);
  }
}

// Helper functions
function detectNodeType(row: Record<string, unknown>): string {
  const type = detectValue(row, ['type', 'node_type', 'nodeType']);
  return type || 'note';
}

function detectName(row: Record<string, unknown>, sheetName: string, rowIndex: number): string {
  const nameKeys = ['name', 'title', 'task', 'subject', 'description', 'label', 'item'];
  const name = detectValue(row, nameKeys);
  if (name) return name;

  // Fallback to first non-empty string value
  for (const value of Object.values(row)) {
    if (typeof value === 'string' && value.trim()) {
      return value.trim();
    }
  }

  return `${sheetName} Row ${rowIndex + 1}`;
}

function detectSummary(row: Record<string, unknown>): string | null {
  const summary = detectValue(row, ['summary', 'description', 'notes', 'excerpt']);
  return summary ? summary.slice(0, 200) : null;
}

function detectValue(row: Record<string, unknown>, keys: string[]): string | null {
  for (const key of keys) {
    // Case-insensitive matching
    const matchedKey = Object.keys(row).find(
      k => k.toLowerCase() === key.toLowerCase()
    );
    if (matchedKey) {
      const value = row[matchedKey];
      if (value !== null && value !== undefined && value !== '') {
        return String(value).trim();
      }
    }
  }
  return null;
}

function detectDate(row: Record<string, unknown>, keys: string[]): string | null {
  const value = detectValue(row, keys);
  if (!value) return null;

  // Already ISO format
  if (/^\d{4}-\d{2}-\d{2}T/.test(value)) return value;

  // Try to parse
  const parsed = new Date(value);
  if (!isNaN(parsed.getTime())) return parsed.toISOString();

  return null;
}

function detectTags(row: Record<string, unknown>): string[] {
  const tagValue = detectValue(row, ['tags', 'labels', 'categories', 'keywords']);
  if (!tagValue) return [];

  // Split by comma or semicolon
  return tagValue.split(/[,;]/).map(t => t.trim()).filter(Boolean);
}

function detectPriority(row: Record<string, unknown>): number {
  const p = detectValue(row, ['priority']);
  if (!p) return 0;

  // Numeric
  const num = parseInt(p, 10);
  if (!isNaN(num)) return Math.min(5, Math.max(0, num));

  // String values
  const lower = p.toLowerCase();
  if (lower === 'high' || lower === 'urgent' || lower === 'critical') return 5;
  if (lower === 'medium' || lower === 'normal') return 3;
  if (lower === 'low') return 1;

  return 0;
}

function parseNumber(value: string | null): number | null {
  if (!value) return null;
  const num = parseFloat(value);
  return isNaN(num) ? null : num;
}
```

2. Run tests:
   ```bash
   npm run test -- --run src/etl/__tests__/ExcelImporter.test.ts
   ```

3. Run typecheck:
   ```bash
   npm run check:types
   ```
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/ExcelImporter.test.ts` passes all tests (GREEN)
    - `npm run check:types` has zero errors
  </verify>
  <done>ExcelImporter implemented and all tests pass.</done>
</task>

<task type="auto">
  <name>Task 3: Add integration test and verify all importers</name>
  <files>src/etl/__tests__/ExcelImporter.test.ts</files>
  <action>
1. Add integration test:

```typescript
describe('ExcelImporter integration', () => {
  it('should work with ImportCoordinator', async () => {
    vi.mocked(XLSX.read).mockReturnValue({
      SheetNames: ['Tasks'],
      Sheets: { Tasks: {} },
    });
    vi.mocked(XLSX.utils.sheet_to_json).mockReturnValue([
      { name: 'Integration Task 1' },
      { name: 'Integration Task 2' },
    ]);

    const { ImportCoordinator } = await import('../coordinator/ImportCoordinator');
    const coordinator = new ImportCoordinator();
    coordinator.registerImporter(['.xlsx', '.xls'], new ExcelImporter());

    const nodes = await coordinator.importFile({
      filename: 'integration.xlsx',
      content: 'base64content',
      encoding: 'base64',
    });

    expect(nodes).toHaveLength(2);
    nodes.forEach(node => {
      expect(() => CanonicalNodeSchema.parse(node)).not.toThrow();
    });
  });
});
```

2. Run full test suite to ensure all importers work:
   ```bash
   npm run test -- --run
   ```

3. Run full quality checks:
   ```bash
   npm run check:types
   npm run check:lint
   ```
  </action>
  <verify>
    - All ExcelImporter tests pass
    - All importer tests pass
    - Full quality checks pass
  </verify>
  <done>ExcelImporter complete. All six importers implemented with comprehensive tests.</done>
</task>

</tasks>

<verification>
1. `npm run test -- --run src/etl/__tests__/ExcelImporter.test.ts` - all tests pass
2. `npm run test -- --run` - all importer tests pass
3. `npm run check:types` - zero TypeScript errors
4. One node per row across all sheets
5. Sheet name used as folder for organization
</verification>

<success_criteria>
1. ExcelImporter parses XLSX/XLS using SheetJS
2. One node per row across all sheets
3. Sheet name stored as folder for filtering
4. LATCH fields mapped with intelligent column detection
5. Mixed data types handled
6. All tests pass with TDD cycle
7. All 6 importers complete and working
</success_criteria>

<output>
After completion, create `.planning/phases/69-file-importers/69-06-SUMMARY.md`
</output>
