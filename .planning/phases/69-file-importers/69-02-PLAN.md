---
phase: 69-file-importers
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/etl/importers/JsonImporter.ts
  - src/etl/__tests__/JsonImporter.test.ts
autonomous: true

must_haves:
  truths:
    - "JsonImporter parses JSON arrays as multiple nodes"
    - "JsonImporter parses JSON objects as single node"
    - "LATCH fields mapped with flexible key detection"
    - "Original JSON structure preserved in content field"
  artifacts:
    - path: "src/etl/importers/JsonImporter.ts"
      provides: "JSON importer extending BaseImporter"
      exports: ["JsonImporter"]
    - path: "src/etl/__tests__/JsonImporter.test.ts"
      provides: "TDD tests for JSON import"
      min_lines: 70
  key_links:
    - from: "src/etl/importers/JsonImporter.ts"
      to: "src/etl/importers/BaseImporter.ts"
      via: "extends BaseImporter"
      pattern: "extends BaseImporter"
---

<objective>
Implement JsonImporter for .json file import using TDD.

Purpose: JSON uses native parsing (fastest, no dependencies), handles both object and array structures, and demonstrates the multi-node pattern for tabular data.

Output: Working JsonImporter that handles objects (single node) and arrays (multiple nodes) with intelligent LATCH mapping.
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/68-import-coordinator/68-01-SUMMARY.md

# Foundation from Phase 68
@src/etl/importers/BaseImporter.ts
@src/etl/types/canonical.ts
@src/etl/id-generation/deterministic.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create failing tests for JsonImporter</name>
  <files>src/etl/__tests__/JsonImporter.test.ts</files>
  <action>
1. Create JsonImporter.test.ts with failing tests covering:
   - Single object -> one node
   - Array of objects -> multiple nodes (one per item)
   - Nested objects handled gracefully
   - Empty array returns empty node array
   - Invalid JSON throws descriptive error
   - LATCH field mapping with flexible key detection:
     - name/title/id -> name
     - created/createdAt/date -> createdAt
     - tags (array or comma-string)
     - folder/category
     - priority (number or string)
   - Deterministic sourceId per array item
   - Original JSON preserved in content field (pretty-printed)

2. Test structure:
```typescript
import { JsonImporter } from '../importers/JsonImporter';
import { CanonicalNodeSchema } from '../types/canonical';
import { FileSource } from '../importers/BaseImporter';

describe('JsonImporter', () => {
  let importer: JsonImporter;

  beforeEach(() => {
    importer = new JsonImporter();
  });

  describe('single object', () => {
    it('should import single object as one node', async () => {
      const source: FileSource = {
        filename: 'single.json',
        content: JSON.stringify({
          name: 'Test Task',
          created: '2024-01-15T10:00:00Z',
          tags: ['work', 'urgent'],
          priority: 'high',
        }),
      };

      const nodes = await importer.import(source);

      expect(nodes).toHaveLength(1);
      expect(nodes[0].name).toBe('Test Task');
      expect(nodes[0].createdAt).toBe('2024-01-15T10:00:00Z');
      expect(nodes[0].tags).toEqual(['work', 'urgent']);
      expect(nodes[0].priority).toBe(5);
    });
  });

  describe('array of objects', () => {
    it('should import array as multiple nodes', async () => {
      const source: FileSource = {
        filename: 'tasks.json',
        content: JSON.stringify([
          { title: 'Task 1', status: 'todo' },
          { title: 'Task 2', status: 'done' },
          { title: 'Task 3', status: 'in-progress' },
        ]),
      };

      const nodes = await importer.import(source);

      expect(nodes).toHaveLength(3);
      expect(nodes[0].name).toBe('Task 1');
      expect(nodes[1].name).toBe('Task 2');
      expect(nodes[2].name).toBe('Task 3');
    });

    it('should generate unique sourceIds per array item', async () => {
      const source: FileSource = {
        filename: 'array.json',
        content: JSON.stringify([
          { name: 'Item 1' },
          { name: 'Item 2' },
        ]),
      };

      const nodes = await importer.import(source);

      expect(nodes[0].sourceId).not.toBe(nodes[1].sourceId);
    });
  });

  describe('edge cases', () => {
    it('should return empty array for empty JSON array', async () => {
      const source: FileSource = {
        filename: 'empty.json',
        content: '[]',
      };

      const nodes = await importer.import(source);

      expect(nodes).toHaveLength(0);
    });

    it('should throw on invalid JSON', async () => {
      const source: FileSource = {
        filename: 'invalid.json',
        content: '{ not valid json }',
      };

      await expect(importer.import(source)).rejects.toThrow(/invalid json/i);
    });
  });

  describe('LATCH mapping', () => {
    it('should detect name from various keys', async () => {
      const cases = [
        { name: 'From name' },
        { title: 'From title' },
        { subject: 'From subject' },
        { description: 'From description' },
      ];

      for (const obj of cases) {
        const nodes = await importer.import({
          filename: 'test.json',
          content: JSON.stringify(obj),
        });
        expect(nodes[0].name).toBe(Object.values(obj)[0]);
      }
    });
  });

  describe('validation', () => {
    it('should produce valid CanonicalNode', async () => {
      const source: FileSource = {
        filename: 'validate.json',
        content: JSON.stringify({ name: 'Validation Test' }),
      };

      const nodes = await importer.import(source);

      expect(() => CanonicalNodeSchema.parse(nodes[0])).not.toThrow();
    });
  });
});
```

3. Run tests to verify they fail (RED phase):
   ```bash
   npm run test -- --run src/etl/__tests__/JsonImporter.test.ts
   ```
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/JsonImporter.test.ts` runs and all tests FAIL
    - Tests cover single object, array, edge cases, LATCH mapping, validation
  </verify>
  <done>Tests written for JsonImporter covering object/array parsing, LATCH mapping, edge cases. All tests fail (RED phase).</done>
</task>

<task type="auto">
  <name>Task 2: Implement JsonImporter to pass tests</name>
  <files>src/etl/importers/JsonImporter.ts</files>
  <action>
1. Create JsonImporter extending BaseImporter:

```typescript
/**
 * JSON Importer for Isometry ETL
 *
 * Parses .json files using native JSON.parse.
 * - Single object -> one node
 * - Array of objects -> multiple nodes
 *
 * LATCH mapping with flexible key detection.
 */

import { v4 as uuidv4 } from 'uuid';
import { BaseImporter, FileSource } from './BaseImporter';
import { CanonicalNode } from '../types/canonical';
import { generateDeterministicSourceId } from '../id-generation/deterministic';

interface ParsedJson {
  data: unknown;
  filename: string;
}

export class JsonImporter extends BaseImporter {
  protected async parse(source: FileSource): Promise<unknown> {
    try {
      const data = JSON.parse(source.content);
      return { data, filename: source.filename };
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      throw new Error(`Invalid JSON in ${source.filename}: ${message}`);
    }
  }

  protected async transform(data: unknown): Promise<CanonicalNode[]> {
    const { data: parsed, filename } = data as ParsedJson;
    const now = new Date().toISOString();

    // Array -> multiple nodes
    if (Array.isArray(parsed)) {
      return parsed.map((item, index) =>
        this.objectToNode(item, filename, index, now)
      );
    }

    // Single object -> one node
    if (typeof parsed === 'object' && parsed !== null) {
      return [this.objectToNode(parsed, filename, 0, now)];
    }

    // Primitive value -> wrap in node
    return [this.primitiveToNode(parsed, filename, now)];
  }

  private objectToNode(
    obj: unknown,
    filename: string,
    index: number,
    now: string
  ): CanonicalNode {
    const data = (obj || {}) as Record<string, unknown>;

    const sourceId = generateDeterministicSourceId(
      `${filename}:${index}`,
      data,
      'json-importer'
    );

    return {
      id: uuidv4(),
      sourceId,
      source: 'json-importer',
      nodeType: detectNodeType(data),
      name: detectName(data, index),
      content: JSON.stringify(data, null, 2),
      summary: detectSummary(data),

      // LATCH: Location
      latitude: (data.latitude || data.lat) as number | null ?? null,
      longitude: (data.longitude || data.lng || data.lon) as number | null ?? null,
      locationName: (data.location_name || data.locationName || data.place) as string | null ?? null,
      locationAddress: (data.address || data.location || data.locationAddress) as string | null ?? null,

      // LATCH: Time
      createdAt: detectDate(data, ['created', 'createdAt', 'created_at', 'date', 'timestamp']) || now,
      modifiedAt: detectDate(data, ['modified', 'modifiedAt', 'modified_at', 'updated', 'updatedAt']) || now,
      dueAt: detectDate(data, ['due', 'dueAt', 'due_at', 'deadline', 'dueDate']) || null,
      completedAt: detectDate(data, ['completed', 'completedAt', 'completed_at', 'done']) || null,
      eventStart: detectDate(data, ['start', 'eventStart', 'startDate', 'start_date']) || null,
      eventEnd: detectDate(data, ['end', 'eventEnd', 'endDate', 'end_date']) || null,

      // LATCH: Category
      folder: (data.folder || data.category || data.group) as string | null ?? null,
      tags: detectTags(data),
      status: (data.status || data.state) as string | null ?? null,

      // LATCH: Hierarchy
      priority: detectPriority(data),
      importance: (data.importance as number) || 0,
      sortOrder: (data.sort_order || data.sortOrder || data.order || 0) as number,

      // Grid
      gridX: 0,
      gridY: 0,

      // Provenance
      sourceUrl: (data.url || data.link || data.source_url) as string | null ?? null,
      deletedAt: null,
      version: 1,

      // Store all original keys for reference
      properties: {
        originalFormat: 'json',
        originalKeys: Object.keys(data),
      },
    };
  }

  private primitiveToNode(value: unknown, filename: string, now: string): CanonicalNode {
    return {
      id: uuidv4(),
      sourceId: generateDeterministicSourceId(filename, { value }, 'json-importer'),
      source: 'json-importer',
      nodeType: 'note',
      name: String(value),
      content: JSON.stringify(value, null, 2),
      summary: null,
      latitude: null,
      longitude: null,
      locationName: null,
      locationAddress: null,
      createdAt: now,
      modifiedAt: now,
      dueAt: null,
      completedAt: null,
      eventStart: null,
      eventEnd: null,
      folder: null,
      tags: [],
      status: null,
      priority: 0,
      importance: 0,
      sortOrder: 0,
      gridX: 0,
      gridY: 0,
      sourceUrl: null,
      deletedAt: null,
      version: 1,
      properties: { originalFormat: 'json', primitiveType: typeof value },
    };
  }
}

// Helper functions
function detectNodeType(data: Record<string, unknown>): string {
  return (data.type || data.nodeType || data.node_type || 'note') as string;
}

function detectName(data: Record<string, unknown>, index: number): string {
  const candidates = ['name', 'title', 'subject', 'description', 'label', 'id'];
  for (const key of candidates) {
    const val = data[key];
    if (typeof val === 'string' && val.length > 0) return val;
  }
  return `Item ${index + 1}`;
}

function detectSummary(data: Record<string, unknown>): string | null {
  const candidates = ['summary', 'description', 'excerpt', 'preview'];
  for (const key of candidates) {
    const val = data[key];
    if (typeof val === 'string') return val.slice(0, 200);
  }
  return null;
}

function detectDate(data: Record<string, unknown>, keys: string[]): string | null {
  for (const key of keys) {
    const val = data[key];
    if (!val) continue;

    // Handle Date objects
    if (val instanceof Date) return val.toISOString();

    // Handle ISO strings
    if (typeof val === 'string') {
      if (/^\d{4}-\d{2}-\d{2}T/.test(val)) return val;
      const parsed = new Date(val);
      if (!isNaN(parsed.getTime())) return parsed.toISOString();
    }

    // Handle timestamps
    if (typeof val === 'number') {
      const parsed = new Date(val);
      if (!isNaN(parsed.getTime())) return parsed.toISOString();
    }
  }
  return null;
}

function detectTags(data: Record<string, unknown>): string[] {
  const tagKeys = ['tags', 'labels', 'categories', 'keywords'];
  for (const key of tagKeys) {
    const val = data[key];
    if (Array.isArray(val)) return val.map(String);
    if (typeof val === 'string') {
      return val.split(/[,;]/).map(t => t.trim()).filter(Boolean);
    }
  }
  return [];
}

function detectPriority(data: Record<string, unknown>): number {
  const p = data.priority;
  if (typeof p === 'number') return Math.min(5, Math.max(0, p));
  if (typeof p === 'string') {
    const lower = p.toLowerCase();
    if (lower === 'high' || lower === 'urgent' || lower === 'critical') return 5;
    if (lower === 'medium' || lower === 'normal') return 3;
    if (lower === 'low') return 1;
    const num = parseInt(p, 10);
    if (!isNaN(num)) return Math.min(5, Math.max(0, num));
  }
  return 0;
}
```

2. Run tests:
   ```bash
   npm run test -- --run src/etl/__tests__/JsonImporter.test.ts
   ```

3. Run typecheck:
   ```bash
   npm run check:types
   ```
  </action>
  <verify>
    - `npm run test -- --run src/etl/__tests__/JsonImporter.test.ts` passes all tests (GREEN)
    - `npm run check:types` has zero errors
  </verify>
  <done>JsonImporter implemented and all tests pass. Handles objects, arrays, primitives with LATCH mapping.</done>
</task>

<task type="auto">
  <name>Task 3: Add integration test with ImportCoordinator</name>
  <files>src/etl/__tests__/JsonImporter.test.ts</files>
  <action>
1. Add integration test:

```typescript
describe('JsonImporter integration', () => {
  it('should work with ImportCoordinator', async () => {
    const { ImportCoordinator } = await import('../coordinator/ImportCoordinator');
    const coordinator = new ImportCoordinator();
    coordinator.registerImporter(['.json'], new JsonImporter());

    const source: FileSource = {
      filename: 'integration.json',
      content: JSON.stringify([
        { name: 'Task 1' },
        { name: 'Task 2' },
      ]),
    };

    const nodes = await coordinator.importFile(source);

    expect(nodes).toHaveLength(2);
    // All nodes validated by CanonicalNodeSchema in coordinator
    nodes.forEach(node => {
      expect(() => CanonicalNodeSchema.parse(node)).not.toThrow();
    });
  });
});
```

2. Run full test suite:
   ```bash
   npm run test -- --run
   ```
  </action>
  <verify>
    - All JsonImporter tests pass
    - Integration with ImportCoordinator works
    - Full test suite passes
  </verify>
  <done>JsonImporter complete with integration test. Ready for Wave 1 parallel execution.</done>
</task>

</tasks>

<verification>
1. `npm run test -- --run src/etl/__tests__/JsonImporter.test.ts` - all tests pass
2. `npm run check:types` - zero TypeScript errors
3. JsonImporter handles object, array, and primitive JSON
4. LATCH fields mapped with flexible key detection
</verification>

<success_criteria>
1. JsonImporter parses JSON using native JSON.parse
2. Single objects produce one node
3. Arrays produce one node per element
4. LATCH fields mapped intelligently
5. Deterministic sourceIds for deduplication
6. All tests pass with TDD cycle
</success_criteria>

<output>
After completion, create `.planning/phases/69-file-importers/69-02-SUMMARY.md`
</output>
