---
phase: 30-apple-notes-data-lifecycle-management
plan: 03
type: execute
wave: 3
depends_on: ["30-01", "30-02"]
files_modified: [
  "native/Sources/Isometry/Verification/DataVerificationPipeline.swift",
  "native/Sources/Isometry/Verification/VerificationEngine.swift",
  "native/Sources/Isometry/Verification/AccuracyMetrics.swift",
  "native/Tests/VerificationTests/DataVerificationPipelineTests.swift"
]
autonomous: true

must_haves:
  truths:
    - "Data verification pipeline compares native vs alto-index data with >99.9% accuracy"
    - "Verification identifies acceptable differences vs data corruption automatically"
    - "Pipeline validates round-trip data integrity for all import/export operations"
    - "Accuracy metrics provide detailed reports on data preservation quality"
  artifacts:
    - path: "native/Sources/Isometry/Verification/DataVerificationPipeline.swift"
      provides: "Comprehensive data verification and comparison system"
      min_lines: 400
      exports: ["verifyDataIntegrity", "compareDataSources", "VerificationResult"]
    - path: "native/Sources/Isometry/Verification/VerificationEngine.swift"
      provides: "Core verification algorithms and accuracy calculations"
      contains: "accuracy measurement algorithms"
    - path: "native/Sources/Isometry/Verification/AccuracyMetrics.swift"
      provides: "Detailed accuracy reporting and metrics collection"
      min_lines: 200
  key_links:
    - from: "DataVerificationPipeline.swift"
      to: "AppleNotesNativeImporter.swift"
      via: "native data verification"
      pattern: "nativeImporter\\.verifyData"
    - from: "DataVerificationPipeline.swift"
      to: "AltoIndexImporter.swift"
      via: "alto-index comparison baseline"
      pattern: "altoIndexImporter\\.validateRoundTrip"
---

<objective>
Implement comprehensive data verification pipeline that ensures >99.9% accuracy by comparing native Apple Notes data against alto-index markdown/YAML data, identifying acceptable differences vs corruption, and providing detailed accuracy metrics for data preservation validation.

Purpose: Establish "data in = data out, or else" correctness principle by implementing rigorous verification that detects data corruption, validates round-trip integrity, and ensures native import maintains fidelity compared to established alto-index baseline.
Output: Production-ready verification pipeline with accuracy metrics, automated comparison, and detailed reporting for data integrity validation
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@native/Sources/Isometry/Import/AltoIndexImporter.swift
@native/Sources/Isometry/Models/Node.swift
@.planning/phases/30-apple-notes-data-lifecycle-management/30-01-PLAN.md
@.planning/phases/30-apple-notes-data-lifecycle-management/30-02-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Implement Core Data Verification Pipeline</name>
  <files>
    native/Sources/Isometry/Verification/DataVerificationPipeline.swift
    native/Sources/Isometry/Verification/VerificationEngine.swift
  </files>
  <action>
    Create comprehensive data verification system that ensures data integrity:

    1. **Verification Pipeline Architecture:**
    - Build pipeline that compares native Notes import vs alto-index import
    - Implement parallel processing for large dataset verification
    - Add verification result aggregation and reporting
    - Create verification task queue with priority handling

    2. **Core Verification Algorithms:**
    - Implement field-by-field comparison for Node objects
    - Add content similarity analysis for text differences
    - Create attachment hash verification for binary content
    - Implement timestamp comparison with acceptable precision tolerance

    3. **Accuracy Measurement:**
    - Calculate preservation accuracy percentage (target: >99.9%)
    - Measure LATCH mapping fidelity (Location, Alphabet, Time, Category, Hierarchy)
    - Compute content integrity scores using string similarity algorithms
    - Track schema conformance validation

    4. **Difference Classification:**
    - Distinguish acceptable differences (formatting, precision) from corruption
    - Classify differences as: Identical, Acceptable, Warning, Critical
    - Implement whitelist for known acceptable transformations
    - Add automatic corruption detection patterns

    5. **Performance Optimization:**
    - Use background processing for verification tasks
    - Implement streaming comparison for large datasets
    - Add progress tracking and cancellation support
    - Cache verification results for repeated operations

    Follow existing AltoIndexImporter.validateRoundTripData patterns for consistency, but extend with comprehensive native vs alto-index comparison.
  </action>
  <verify>
    swift build && swift test --filter VerificationEngineTests
  </verify>
  <done>
    Verification pipeline accurately compares data sources, classifies differences appropriately, and provides detailed accuracy measurements with >99.9% target validation
  </done>
</task>

<task type="auto">
  <name>Build Comprehensive Accuracy Metrics System</name>
  <files>
    native/Sources/Isometry/Verification/AccuracyMetrics.swift
  </files>
  <action>
    Implement detailed accuracy reporting and metrics collection system:

    1. **Accuracy Calculation Framework:**
    - Implement weighted accuracy scoring across different data elements
    - Calculate field-level preservation rates (title, content, dates, tags, folders)
    - Measure attachment preservation accuracy including metadata
    - Compute overall data integrity score with confidence intervals

    2. **LATCH Mapping Verification:**
    - Location: Verify location data preservation (lat/lng, addresses)
    - Alphabet: Validate title and name field accuracy
    - Time: Check temporal data preservation (created, modified, due dates)
    - Category: Verify folder and tag classification accuracy
    - Hierarchy: Validate relationship and structure preservation

    3. **Content Integrity Analysis:**
    - Implement sophisticated text similarity algorithms (Levenshtein, Jaro-Winkler)
    - Add markdown format preservation verification
    - Check rich text formatting and structure retention
    - Validate special character and emoji preservation

    4. **Detailed Reporting:**
    - Generate comprehensive verification reports with statistics
    - Create visual accuracy dashboards with charts and metrics
    - Provide drill-down capability for specific data discrepancies
    - Export verification results in multiple formats (JSON, CSV, PDF)

    5. **Benchmarking and Trends:**
    - Track accuracy metrics over time
    - Compare verification results across different data sources
    - Identify patterns in data preservation issues
    - Provide recommendations for improving accuracy

    Use existing AltoIndexImporter accuracy calculation patterns as baseline, extending with comprehensive native comparison capabilities.
  </action>
  <verify>
    swift build && swift test --filter AccuracyMetricsTests
  </verify>
  <done>
    Accuracy metrics system provides detailed preservation analysis, LATCH mapping validation, content integrity scores, and comprehensive reporting with trend analysis
  </done>
</task>

<task type="auto">
  <name>Create Comprehensive Verification Test Suite</name>
  <files>
    native/Tests/VerificationTests/DataVerificationPipelineTests.swift
  </files>
  <action>
    Implement thorough test coverage for data verification system:

    1. **Accuracy Testing:**
    - Test perfect preservation scenarios (100% accuracy expected)
    - Test acceptable difference scenarios (formatting, precision)
    - Test data corruption detection and classification
    - Verify accuracy calculation algorithms with known datasets

    2. **Comparison Algorithm Testing:**
    - Test text similarity algorithms with various content types
    - Verify timestamp comparison with different precision levels
    - Test attachment hash verification with binary content
    - Validate folder hierarchy comparison accuracy

    3. **Performance Testing:**
    - Benchmark verification speed with large datasets (10k+ notes)
    - Test memory usage during bulk verification operations
    - Verify background processing doesn't impact UI performance
    - Test concurrent verification tasks and resource management

    4. **Edge Case Testing:**
    - Test verification with corrupted or incomplete data
    - Verify handling of missing attachments or broken links
    - Test Unicode, emoji, and special character preservation
    - Validate behavior with empty or minimal datasets

    5. **Integration Testing:**
    - Test end-to-end verification pipeline with real Notes data
    - Verify integration with both native and alto-index importers
    - Test verification result storage and retrieval
    - Validate reporting generation and export functionality

    6. **Property-Based Testing:**
    - Generate random Note datasets for comprehensive testing
    - Test invariants: verification should be deterministic and repeatable
    - Verify accuracy metrics are mathematically consistent
    - Test round-trip verification with generated data

    Include stress testing with datasets containing 50k+ notes to validate enterprise-scale performance.
  </action>
  <verify>
    swift test --filter DataVerificationPipelineTests && echo "All verification tests passing with >99% accuracy on test datasets"
  </verify>
  <done>
    Comprehensive test suite validates verification accuracy, performance, edge cases, integration points, and property-based invariants with enterprise-scale datasets
  </done>
</task>

</tasks>

<verification>
1. Run complete verification test suite: `swift test`
2. Execute verification pipeline on known good dataset (should achieve >99.9% accuracy)
3. Test verification with intentionally corrupted data (should detect all corruption)
4. Validate performance with large dataset (10k+ notes in <30 seconds)
5. Generate verification report and confirm detailed metrics accuracy
6. Test round-trip verification with various data types and structures
</verification>

<success_criteria>
- Verification pipeline achieves >99.9% accuracy on production Notes datasets
- System correctly distinguishes acceptable differences from data corruption
- Accuracy metrics provide detailed, actionable reporting on data preservation
- Performance handles 10k+ notes verification in under 30 seconds
- Test suite achieves >99% code coverage with property-based validation
- Integration with existing importers maintains backward compatibility
- Verification reports provide clear guidance for data quality improvement
</success_criteria>

<output>
After completion, create `.planning/phases/30-apple-notes-data-lifecycle-management/30-03-SUMMARY.md`
</output>