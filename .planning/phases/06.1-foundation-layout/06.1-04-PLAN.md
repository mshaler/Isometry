---
phase: 06.1-foundation-layout
plan: 04
type: execute
wave: 2
depends_on: ["06.1-01", "06.1-02"]
files_modified: [
  "native/Sources/Isometry/Utils/PerformanceMonitor.swift",
  "native/Sources/Isometry/Views/Notebook/NotebookPerformanceView.swift",
  "native/Sources/Isometry/ProductionVerification/NotebookPerformanceValidator.swift"
]
autonomous: true

must_haves:
  truths:
    - "Performance monitoring tracks notebook-specific operations"
    - "60fps target is monitored for notebook layout rendering"
    - "Database query performance is tracked for notebook cards"
    - "Performance metrics are accessible during development"
  artifacts:
    - path: "native/Sources/Isometry/Utils/PerformanceMonitor.swift"
      provides: "Notebook performance tracking methods"
      contains: "func startNotebookRender"
    - path: "native/Sources/Isometry/Views/Notebook/NotebookPerformanceView.swift"
      provides: "Debug performance overlay for notebook"
      exports: ["NotebookPerformanceView"]
    - path: "native/Sources/Isometry/ProductionVerification/NotebookPerformanceValidator.swift"
      provides: "Performance validation for production readiness"
      contains: "func validateNotebookPerformance"
  key_links:
    - from: "NotebookContentView"
      to: "PerformanceMonitor"
      via: "render time tracking"
      pattern: "PerformanceMonitor.*startNotebookRender"
    - from: "NotebookPerformanceView"
      to: "PerformanceMonitor"
      via: "metrics display"
      pattern: "PerformanceMonitor\.shared"
---

<objective>
Extend existing performance monitoring infrastructure to track notebook-specific operations and ensure 60fps rendering target is maintained.

Purpose: Provide performance visibility and validation for notebook workflow to maintain native app quality standards
Output: Performance monitoring, debug views, and validation tools specific to notebook operations
</objective>

<execution_context>
@/Users/mshaler/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mshaler/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@native/Sources/Isometry/Utils/PerformanceMonitor.swift
@native/Sources/Isometry/ProductionVerification/PerformanceValidator.swift
@.planning/phases/06.1-foundation-layout/06.1-01-PLAN.md
@.planning/phases/06.1-foundation-layout/06.1-02-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend PerformanceMonitor for notebook operations</name>
  <files>native/Sources/Isometry/Utils/PerformanceMonitor.swift</files>
  <action>
    Add notebook-specific performance tracking to existing PerformanceMonitor.swift:

    Add new properties:
    ```swift
    private var notebookRenderTimes: [TimeInterval] = []
    private var notebookCardQueryTimes: [TimeInterval] = []
    private var componentResizeTimes: [TimeInterval] = []
    ```

    Add new methods following existing patterns:
    ```swift
    // MARK: - Notebook Performance Tracking

    /// Start measuring notebook layout render time
    public func startNotebookRender() -> OSSignpostID {
        let id = OSSignpostID(log: log)
        os_signpost(.begin, log: log, name: "Notebook Render", signpostID: id)
        return id
    }

    /// End measuring notebook layout render time
    public func endNotebookRender(_ id: OSSignpostID, layoutType: String = "") {
        os_signpost(.end, log: log, name: "Notebook Render", signpostID: id,
                   formatString: "Layout: %@", layoutType)

        lock.lock()
        defer { lock.unlock() }

        let endTime = CACurrentMediaTime()
        if let startTime = signpostTimes.removeValue(forKey: id) {
            let renderTime = endTime - startTime
            notebookRenderTimes.append(renderTime)
            limitArray(&notebookRenderTimes, to: maxSamples)

            if renderTime > Self.targetFrameTime {
                os_log(.error, log: metricsLog,
                       "Notebook render exceeded target: %.2fms (target: %.2fms)",
                       renderTime * 1000, Self.targetFrameTime * 1000)
            }
        }
    }

    /// Track notebook card database queries
    public func recordNotebookCardQuery(_ duration: TimeInterval, operation: String) {
        lock.lock()
        defer { lock.unlock() }

        notebookCardQueryTimes.append(duration)
        limitArray(&notebookCardQueryTimes, to: maxSamples)

        if duration > Self.maxQueryTime {
            os_log(.error, log: metricsLog,
                   "Notebook card query exceeded limit: %@ took %.2fms",
                   operation, duration * 1000)
        }
    }

    /// Track component resize performance
    public func recordComponentResize(_ duration: TimeInterval) {
        lock.lock()
        defer { lock.unlock() }

        componentResizeTimes.append(duration)
        limitArray(&componentResizeTimes, to: maxSamples)
    }

    // MARK: - Notebook Metrics

    public var notebookMetrics: NotebookPerformanceMetrics {
        lock.lock()
        defer { lock.unlock() }

        return NotebookPerformanceMetrics(
            averageRenderTime: notebookRenderTimes.isEmpty ? 0 : notebookRenderTimes.reduce(0, +) / Double(notebookRenderTimes.count),
            maxRenderTime: notebookRenderTimes.max() ?? 0,
            averageQueryTime: notebookCardQueryTimes.isEmpty ? 0 : notebookCardQueryTimes.reduce(0, +) / Double(notebookCardQueryTimes.count),
            maxQueryTime: notebookCardQueryTimes.max() ?? 0,
            averageResizeTime: componentResizeTimes.isEmpty ? 0 : componentResizeTimes.reduce(0, +) / Double(componentResizeTimes.count),
            renderSampleCount: notebookRenderTimes.count,
            querySampleCount: notebookCardQueryTimes.count
        )
    }
    ```

    Add NotebookPerformanceMetrics struct after existing structs.
    Follow existing code style and patterns exactly.
  </action>
  <verify>PerformanceMonitor builds with notebook tracking methods</verify>
  <done>PerformanceMonitor supports notebook-specific performance tracking</done>
</task>

<task type="auto">
  <name>Task 2: Create NotebookPerformanceValidator for production verification</name>
  <files>native/Sources/Isometry/ProductionVerification/NotebookPerformanceValidator.swift</files>
  <action>
    Create NotebookPerformanceValidator following existing production verification patterns:

    ```swift
    import Foundation
    import SwiftUI

    /// Performance validation for notebook functionality
    public final class NotebookPerformanceValidator: @unchecked Sendable {
        public static let shared = NotebookPerformanceValidator()

        private let performanceMonitor = PerformanceMonitor.shared

        private init() {}

        /// Validate notebook performance meets production standards
        public func validateNotebookPerformance() async -> NotebookPerformanceResult {
            let metrics = performanceMonitor.notebookMetrics

            var issues: [PerformanceIssue] = []

            // Validate render performance
            if metrics.averageRenderTime > PerformanceMonitor.targetFrameTime {
                issues.append(PerformanceIssue(
                    severity: .error,
                    category: "Render Performance",
                    description: "Average notebook render time exceeds 16.67ms target",
                    currentValue: "\(String(format: "%.2f", metrics.averageRenderTime * 1000))ms",
                    targetValue: "\(String(format: "%.2f", PerformanceMonitor.targetFrameTime * 1000))ms",
                    impact: "User will experience dropped frames during notebook usage"
                ))
            }

            // Validate query performance
            if metrics.averageQueryTime > PerformanceMonitor.maxQueryTime {
                issues.append(PerformanceIssue(
                    severity: .warning,
                    category: "Database Performance",
                    description: "Notebook card queries are slower than recommended",
                    currentValue: "\(String(format: "%.2f", metrics.averageQueryTime * 1000))ms",
                    targetValue: "\(String(format: "%.2f", PerformanceMonitor.maxQueryTime * 1000))ms",
                    impact: "Notebook card loading may feel sluggish"
                ))
            }

            // Validate sample count (need sufficient data)
            if metrics.renderSampleCount < 10 {
                issues.append(PerformanceIssue(
                    severity: .info,
                    category: "Test Coverage",
                    description: "Insufficient notebook render samples for reliable metrics",
                    currentValue: "\(metrics.renderSampleCount) samples",
                    targetValue: "10+ samples",
                    impact: "Performance validation may not be accurate"
                ))
            }

            return NotebookPerformanceResult(
                isValid: issues.filter { $0.severity == .error }.isEmpty,
                metrics: metrics,
                issues: issues,
                testDate: Date()
            )
        }
    }

    // MARK: - Supporting Types

    public struct NotebookPerformanceMetrics {
        public let averageRenderTime: TimeInterval
        public let maxRenderTime: TimeInterval
        public let averageQueryTime: TimeInterval
        public let maxQueryTime: TimeInterval
        public let averageResizeTime: TimeInterval
        public let renderSampleCount: Int
        public let querySampleCount: Int
    }

    public struct NotebookPerformanceResult {
        public let isValid: Bool
        public let metrics: NotebookPerformanceMetrics
        public let issues: [PerformanceIssue]
        public let testDate: Date
    }

    public struct PerformanceIssue {
        public let severity: Severity
        public let category: String
        public let description: String
        public let currentValue: String
        public let targetValue: String
        public let impact: String

        public enum Severity {
            case info, warning, error
        }
    }
    ```

    Follow existing production verification code patterns and error handling.
  </action>
  <verify>NotebookPerformanceValidator builds and can validate performance metrics</verify>
  <done>Production verification includes notebook performance validation</done>
</task>

</tasks>

<verification>
1. Build native project: `cd native && xcodebuild -scheme Isometry build`
2. Verify performance monitoring integration compiles
3. Test that notebook operations generate performance metrics
4. Run performance validation to ensure proper metric collection
</verification>

<success_criteria>
- PerformanceMonitor tracks notebook-specific render and query performance
- Performance metrics can detect when 60fps target is not met
- Notebook performance validation identifies production readiness issues
- Debug tools provide visibility into performance bottlenecks
- Monitoring integrates seamlessly with existing performance infrastructure
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-foundation-layout/06.1-04-SUMMARY.md`
</output>